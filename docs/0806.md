# 机器学习中的贝叶斯定理

> 原文:[https://www . javatpoint . com/Bayes-机器学习定理](https://www.javatpoint.com/bayes-theorem-in-machine-learning)

机器学习是人工智能最新兴的技术之一。我们生活在 21 世纪，这个世纪完全由新技术和小工具所驱动，其中一些还没有被使用，很少能充分发挥其潜力。同样，机器学习也是一项仍处于发展阶段的技术。有许多概念使机器学习成为一种更好的技术，如监督学习、无监督学习、强化学习、感知器模型、神经网络等。在这篇《机器学习中的贝叶斯定理》中，我们将讨论机器学习定理的另一个最重要的概念，即 ***贝叶斯定理*** 。但是在开始这个主题之前，你应该对这个定理有基本的了解，比如什么是贝叶斯定理，为什么它被用在机器学习中，贝叶斯定理在机器学习中的例子等等。那么，让我们开始简单介绍一下贝叶斯定理。

![Bayes Theorem in Machine learning](../Images/268dd6ca9b22a83a5c6a80f7ad69a52d.png)

## 机器学习中的贝叶斯定理介绍

贝叶斯定理是由一位名叫托马斯·贝叶斯先生的英国统计学家、哲学家和长老会牧师在 17 世纪的 T2 给出的。贝叶斯在决策理论中提供了他们的思想，决策理论被广泛用于重要的数学概念，如概率。贝叶斯定理也广泛应用于机器学习中，在机器学习中，我们需要精确地预测类。贝叶斯定理的一个重要概念**贝叶斯方法**用于计算包括分类任务的机器学习应用中的条件概率。此外，贝叶斯定理的简化版本(朴素贝叶斯分类)也被用于减少计算时间和项目的平均成本。

贝叶斯定理也有一些其他的名称，如**贝叶斯规则或贝叶斯定律。*贝叶斯定理有助于用随机知识*** 确定事件发生的概率。它用于计算一个事件发生而另一个事件已经发生的概率。将条件概率和边际概率联系起来是最好的方法。

简单来说，我们可以说贝叶斯定理有助于贡献更准确的结果。

贝叶斯定理用于估计值的精度，并提供了一种计算条件概率的方法。然而，这是一个虚伪的简单计算，但它被用来轻松计算直觉经常失败的事件的条件概率。一些数据科学家假设贝叶斯定理在金融行业应用最广泛，但事实并非如此。除了金融以外，贝叶斯定理还广泛应用于卫生和医疗、研究和调查行业、航空部门等。

## 什么是贝叶斯定理？

贝叶斯定理是最流行的机器学习概念之一，它有助于计算一个事件在知识不确定的情况下发生的概率，而另一个事件已经发生。

贝叶斯定理可以利用乘积规则和已知事件 Y 的事件 X 的条件概率导出:

*   根据乘积法则，我们可以用已知事件 Y 表示为事件 X 的概率如下；

```

P(X ? Y)= P(X|Y) P(Y)       {equation 1}

```

*   此外，事件 Y 与已知事件 X 的概率:

```

P(X ? Y)= P(Y|X) P(X)       {equation 2}

```

数学上，贝叶斯定理可以用右手边的两个方程组合来表示。我们将获得:

![Bayes Theorem in Machine learning](../Images/0d6dae9d2cb1a7c38f8cd5f32df006ae.png)

这里，事件 X 和 Y 都是独立的事件，这意味着两个事件的结果概率并不相互依赖。

上述方程称为贝叶斯规则或贝叶斯定理。

*   P(X|Y)称为**后验**，我们需要计算。定义为考虑证据后的更新概率。
*   P(Y|X)称为可能性。假设为真时的证据概率。
*   P(X)称为**先验概率**，在考虑证据之前假设的概率
*   P(Y)称为边际概率。它被定义为任何考虑下的证据概率。

因此，贝叶斯定理可以写成:

**后验=可能性*先验/证据**

## 贝叶斯定理的先决条件

在学习贝叶斯定理时，我们需要理解几个重要的概念。这些措施如下:

**1。实验**

实验被定义为在受控条件下进行的有计划的操作，如投掷硬币、抽牌和掷骰子等。

**2。样本空间**

在实验过程中，我们得到的结果被称为可能的结果，一个事件所有可能结果的集合被称为样本空间。例如，如果我们正在掷骰子，样本空间将是:

S1 = {1，2，3，4，5，6}

同样，如果我们的实验与抛硬币和记录其结果有关，那么样本空间将是:

S2 = {头，尾}

**3。事件**

事件被定义为实验中样本空间的子集。此外，它也被称为结果集。

![Bayes Theorem in Machine learning](../Images/a7d43be72788b1cc3abb13ab1322766d.png)

假设在我们掷骰子的实验中，有两个事件 A 和 B 是这样的；

A =获得偶数时的事件= {2，4，6}

B =数字大于 4 时的事件= {5，6}

*   **事件发生的概率 A ''P(A)''** =有利结果数/可能结果总数
    P(E) = 3/6 =1/2 =0.5
*   类似地，**事件 B ''P(B)''** 的概率=有利结果数/可能结果总数
    =2/6
    =1/3
    =0.333
*   **事件 A 和 B 的结合:**T2【A∪B = { 2，4，5，6 }
    T4】
*   **事件 A 和 B 的交集:**T2【A∪B = { 6 }
    T4】
*   **分离事件:**如果事件 A 和事件 B 的交集为空集或空，则此类事件也称为**分离事件**或**互斥事件**。
    ![Bayes Theorem in Machine learning](../Images/414913ab6060fa9c47f581a018f88f76.png)

**4。随机变量:**

它是一个实值函数，有助于在样本空间和实验的实线之间进行映射。随机变量取一些随机值，每个值都有一定的概率。然而，它既不是随机的，也不是一个变量，而是一个函数，可以是离散的，连续的，也可以是两者的组合。

**5。穷尽事件:**

顾名思义，一次至少发生一个事件的一组事件，称为实验的穷尽事件。

因此，两个事件 A 和 B 被认为是穷尽的，如果 A 或 B 肯定同时发生，并且两者是互斥的，例如，当投掷硬币时，它要么是头，要么可能是尾。

**6。独立事件:**

当一个事件的发生不影响另一个事件的发生时，两个事件被认为是独立的。简单地说，我们可以说两个事件的结果概率并不相互依赖。

在数学上，两个事件 A 和 B 被认为是独立的，如果:

P(A∪B)= P(AB)= P(A)* P(B)

**7。条件概率:**

条件概率被定义为一个事件 A 的概率，假设另一个事件 B 已经发生(即一个条件 B)。这由 P(A|B)表示，我们可以将其定义为:

P(A | B)= P(A∪B)/P(B)

**8。边际概率:**

边际概率被定义为事件 A 独立于任何其他事件 b 发生的概率。此外，它被认为是任何考虑下的证据概率。

P(A) = P(A|B)*P(B) + P(A|~B)*P(~B)

![Bayes Theorem in Machine learning](../Images/04c72e1c58b0c83fa856baa6bd804159.png)

这里~B 代表 B 不发生的事件。

## 机器学习中如何应用贝叶斯定理或贝叶斯规则？

贝叶斯定理帮助我们用 P(A|B)、P(B)和 P(A)来计算单个项 P(B|A)。在我们有概率 P(A|B)、P(B)和 P(A)并且需要确定第四项的情况下，这个规则非常有帮助。

朴素贝叶斯分类器是贝叶斯定理最简单的应用之一，用于分类算法中，根据准确性、速度和类别来分离数据。

让我们通过下面的例子来理解贝叶斯定理在机器学习中的应用。

假设，我们有一个带有 I 属性的向量 A。这意味着

A = A1，A2，A3，A4………Ai

此外，我们有 n 个班级，分别代表 C1、C2、C3、C4。

这是给我们的两个条件，我们在机器语言上工作的分类器必须预测 A，我们的分类器必须选择的第一件事将是最好的可能类。所以，借助贝叶斯定理，我们可以把它写成:

P(置信区间/置信区间)= [ P(置信区间/置信区间)* P(置信区间)] / P(置信区间)

这里；

P(A)是与条件无关的实体。

P(A)将在整个类别中保持不变，这意味着它不会随着类别的变化而改变其值。为了最大化 P(置信区间/置信区间)，我们必须最大化术语 P(置信区间/置信区间)* P(置信区间)的值。

概率列表上有 n 个数字类，让我们假设任何一个类成为正确答案的可能性都是一样的。考虑到这个因素，我们可以说:

P(C1)=P(C2)-P(C3)=P(C4)=…..=P(Cn)。

这个过程有助于我们减少计算成本和时间。这就是贝叶斯定理在机器学习中的重要作用，朴素贝叶斯定理简化了条件概率任务而不影响精度。因此，我们可以得出结论:

P(Ai/C)= P(A1/C)* P(A2/C)* P(A3/C)*……* P(An/C)

因此，通过使用机器学习中的贝叶斯定理，我们可以很容易地描述较小事件的可能性。

## 什么是机器学习中的朴素贝叶斯分类器

朴素贝叶斯定理也是一种有监督的算法，它基于贝叶斯定理，用于解决分类问题。它是机器学习中最简单有效的分类算法之一，使我们能够建立各种最大似然模型进行快速预测。它是一个概率分类器，意味着它基于一个对象的概率进行预测。一些流行的朴素贝叶斯算法是**垃圾邮件过滤、情感分析和文章分类。**

### 朴素贝叶斯分类器在机器学习中的优势:

*   它是计算条件概率和文本分类问题最简单有效的方法之一。
*   朴素贝叶斯分类器算法优于独立预测假设成立的所有其他模型。
*   它比其他模型更容易实现。
*   它需要少量的训练数据来估计测试数据，从而最小化训练时间周期。
*   它可以用于二进制以及多类分类。

### 朴素贝叶斯分类器在机器学习中的缺点:

使用朴素贝叶斯分类器算法的主要缺点是，它限制了独立预测器的假设，因为它隐含地假设所有属性都是独立或不相关的，但是在现实生活中，获得相互独立的属性是不可行的。

## 结论

然而，我们生活在一个技术世界里，一切都基于各种处于发展阶段的新技术，但由于缺乏现有的经典定理和算法，这些技术仍然是不完整的。贝叶斯定理也是机器学习中最常用的例子。贝叶斯定理在机器学习中有很多应用。在与分类相关的问题中，它是所有其他算法中最优选的方法之一。因此，我们可以说机器学习高度依赖于贝叶斯定理。本文讨论了贝叶斯定理，贝叶斯定理在机器学习中的应用，朴素贝叶斯分类器等。

* * *