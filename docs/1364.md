# 窘

> 原文：<https://www.javatpoint.com/keras-layers>

Keras 包含广泛的预定义图层，并且允许您创建自己的图层。在构建 Keras 模型时，它充当主要的构建模块。在 Keras 中，每当每一层接收到输入时，它都会执行一些计算，从而得到转换后的信息。一层的输出作为输入馈送到另一层。

Keras Core 层包括**密集**层，它是点积加偏置，**激活**层，它传递函数或神经元形状，**脱落**层，它在每次训练更新时随机地将输入单元的一部分设置为零以避免过拟合的问题，以及**λ**层，它像层的对象一样包裹任意表达式，等等。

Keras 卷积图层利用过滤器创建从 1D 到 3D 的要素地图。它包括大多数常见的不变量，例如，每个维度的**裁剪**和**转置卷积**图层。 **2D 卷积**用于图像识别，因为它是受视觉皮层的启发。

降尺度层主要被称为汇集层，从 1D 延伸到三维。它还包括最常见的变体，如最大池和平均池。局部连接的层充当卷积层，只是权重保持不共享。噪声层消除了过拟合的问题。递归层，包括简单层、门控层、LSTM 层等。在像语言处理这样的应用程序中实现。

以下是每个 Keras 层的一些常用方法:

*   **get_weights()** :它以 numpy 数组列表的形式生成图层的权重。
*   **设置权重(权重)**:设置图层的权重，其形状与 numpy 数组列表中 get_weights()输出的形状相似。
*   **get_config()** :返回包含图层配置的字典，以便从其配置通过实例化；

```

layer = Dense(32)
config = layer.get_config()
reconstructed_layer = Dense.from_config(config)

```

或者，

```

from keras import layers

config = layer.get_config()
layer = layers.deserialize({'class_name': layer.__class__.__name__,
                            'config': config})

```

如果层不是共享层，或者我们可以说该层由单个节点组成，那么我们可以通过以下方式获得它的输入张量、输出张量、输入形状和输出形状；

*   投入
*   输出
*   输入形状
*   输出形状

否则，如果层包含几个节点，那么在这种情况下，您可以使用下面给出的方法；

*   get_input_at(节点 _ 索引)
*   get_output_at(节点 _ 索引)
*   get_input_shape_at(节点索引)
*   get_output_shape_at(节点 _ 索引)

## 核心玩家

```

1\. keras.layers.Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)
2\. keras.layers.Activation(activation)
3\. keras.layers.Dropout(rate, noise_shape=None, seed=None)
4\. keras.layers.Flatten()
5\. keras.engine.topology.Input()
6\. keras.layers.Reshape(target_shape)
7\. keras.layers.Permute(dims)
8\. keras.layers.RepeatVector(n)
9\. keras.layers.Lambda(function, output_shape=None, mask=None, arguments=None)
10\. keras.layers.ActivityRegularization(l1=0.0, l2=0.0)
11\. keras.layers.Masking(mask_value=0.0)

```

## 卷积层

```

1\. keras.layers.Conv1D(filters, kernel_size, strides=1, padding='valid', dilation_rate=1, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)
2\. keras.layers.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)
3\. keras.layers.SeparableConv2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, depth_multiplier=1, activation=None, use_bias=True, depthwise_initializer='glorot_uniform', pointwise_initializer='glorot_uniform', bias_initializer='zeros', depthwise_regularizer=None, pointwise_regularizer=None, bias_regularizer=None, activity_regularizer=None, depthwise_constraint=None, pointwise_constraint=None, bias_constraint=None)
4\. keras.layers.Conv2DTranspose(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)
5\. keras.layers.Conv3D(filters, kernel_size, strides=(1, 1, 1), padding='valid', data_format=None, dilation_rate=(1, 1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)
6\. keras.layers.Cropping1D(cropping=(1, 1))
7\. keras.layers.Cropping2D(cropping=((0, 0), (0, 0)), data_format=None)
8\. keras.layers.Cropping3D(cropping=((1, 1), (1, 1), (1, 1)), data_format=None)
9\. keras.layers.UpSampling1D(size=2)
10\. keras.layers.UpSampling2D(size=(2, 2), data_format=None)
11\. keras.layers.UpSampling3D(size=(2, 2, 2), data_format=None)
12\. keras.layers.ZeroPadding1D(padding=1)
13\. keras.layers.ZeroPadding2D(padding=(1, 1), data_format=None)
14\. keras.layers.ZeroPadding3D(padding=(1, 1, 1), data_format=None)

```

## 汇集层

```

1\. keras.layers.MaxPooling1D(pool_size=2, strides=None, padding='valid')
2\. keras.layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)
3\. keras.layers.MaxPooling3D(pool_size=(2, 2, 2), strides=None, padding='valid', data_format=None)
4\. keras.layers.AveragePooling1D(pool_size=2, strides=None, padding='valid')
5\. keras.layers.AveragePooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)
6\. keras.layers.AveragePooling3D(pool_size=(2, 2, 2), strides=None, padding='valid', data_format=None)
7\. keras.layers.GlobalMaxPooling1D()
8\. keras.layers.GlobalAveragePooling1D()
9\. keras.layers.GlobalMaxPooling1D()
10\. keras.layers.GlobalMaxPooling2D(data_format=None)
11\. keras.layers.GlobalAveragePooling2D(data_format=None)

```

## 局部连通层

```

1\. keras.layers.LocallyConnected1D(filters, kernel_size, strides=1, padding='valid', data_format=None, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)
2\. keras.layers.LocallyConnected2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)

```

## RNN 层

```

1\. keras.layers.RNN(cell, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False)
2\. keras.layers.SimpleRNN(units, activation='tanh', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False)
3\. keras.layers.GRU(units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False)
4\. keras.layers.LSTM(units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False)
5\. keras.layers.ConvLSTM2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, return_sequences=False, go_backwards=False, stateful=False, dropout=0.0, recurrent_dropout=0.0)
6\. keras.layers.SimpleRNNCell(units, activation='tanh', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0)
7\. keras.layers.GRUCell(units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1)
8\. keras.layers.LSTMCell(units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1)
9\. keras.layers.StackedRNNCells(cells)
10\. keras.layers.CuDNNGRU(units, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, return_sequences=False, return_state=False, stateful=False)
11\. keras.layers.CuDNNLSTM(units, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, return_sequences=False, return_state=False, stateful=False)

```

## 噪声层

```

1\. keras.layers.GaussianNoise(stddev)
2\. keras.layers.GaussianDropout(rate)
3\. keras.layers.AlphaDropout(rate, noise_shape=None, seed=None)

```

## 层包装

```

1\. keras.layers.GaussianNoise(stddev)
2\. keras.layers.GaussianDropout(rate)
3\. keras.layers.AlphaDropout(rate, noise_shape=None, seed=None)

```

## 标准化层

```

1\. keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)

```

## 嵌入层

```

1\. keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None)

```

## 高级激活层

```

1\. keras.layers.LeakyReLU(alpha=0.3)
2\. keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=None)
3\. keras.layers.ELU(alpha=1.0)
4\. keras.layers.ThresholdedReLU(theta=1.0)
5\. keras.layers.Softmax(axis=-1)

```

* * *