# k-均值聚类算法

> 原文:[https://www . javatpoint . com/k-means-聚类-机器学习中的算法](https://www.javatpoint.com/k-means-clustering-algorithm-in-machine-learning)

K-Means 聚类是一种无监督学习算法，用于解决机器学习或数据科学中的聚类问题。在这个主题中，我们将学习什么是 k-means 聚类算法，算法是如何工作的，以及 K-means 聚类的 Python 实现。

## 什么是 K 均值算法？

K-Means 聚类是一种[无监督学习算法](https://www.javatpoint.com/unsupervised-machine-learning)，将未标记的数据集分组到不同的聚类中。这里 K 定义了流程中需要创建的预定义簇数，好像 K=2 会有两个簇，对于 K=3 会有三个簇，以此类推。

> 它是一种迭代算法，将未标记的数据集分成 k 个不同的聚类，每个数据集只属于一个具有相似属性的组。

它允许我们将数据聚类到不同的组中，并提供了一种方便的方法来自行发现未标记数据集中的组类别，而无需任何训练。

这是一种基于质心的算法，其中每个聚类都与一个质心相关联。该算法的主要目的是最小化数据点和它们对应的聚类之间的距离总和。

该算法以未标记数据集为输入，将数据集划分为 k 个聚类，并重复该过程，直到没有找到最佳聚类。k 的值应该在这个算法中预先确定。

k-means [聚类](clustering-in-machine-learning)算法主要执行两个任务:

*   通过迭代过程确定 K 个中心点或质心的最佳值。
*   将每个数据点分配到其最近的 k 中心。那些靠近特定 k 中心的数据点会创建一个集群。

因此，每个集群都有一些共性的数据点，并且远离其他集群。

下图解释了 K 均值聚类算法的工作原理:

![K-Means Clustering Algorithm](../Images/03483b62bc00ea2537c910935a5327c7.png)

## K 均值算法是如何工作的？

K-Means 算法的工作原理将在以下步骤中解释:

**步骤-1:** 选择数字 K 决定簇数。

**第 2 步:**选择随机 K 点或质心。(它可以是输入数据集中的其他数据)。

**步骤-3:** 将每个数据点分配到它们最近的质心，这将形成预定义的 K 个聚类。

**步骤-4:** 计算方差并放置每个聚类的新质心。

**步骤-5:** 重复第三步，这意味着将每个数据点重新分配给每个聚类的新的最近质心。

**步骤-6:** 如果发生任何重新分配，则转到步骤-4，否则转到完成。

**第 7 步**:模型准备好了。

让我们通过视觉图来理解上面的步骤:

假设我们有两个变量 M1 和 M2。这两个变量的 x-y 轴散点图如下所示:

![K-Means Clustering Algorithm](../Images/125498fb1ba242c0b5cc6a2550b3f639.png)

*   让我们取聚类数 K，即 K=2，来识别数据集并将其放入不同的聚类中。这意味着我们将尝试将这些数据集分成两个不同的集群。
*   我们需要选择一些随机的 k 点或质心来形成聚类。这些点可以是数据集中的点，也可以是任何其他点。所以，这里我们选择下面两点作为 k 点，这不是我们数据集的一部分。考虑下图:
    ![K-Means Clustering Algorithm](../Images/fdf176661f603d7886342f33c65c846a.png)
*   现在我们将散点图的每个数据点分配给它最近的 K 点或质心。我们将通过应用我们所学的一些数学来计算两点之间的距离来计算它。所以，我们将在两个质心之间画一个中间值。考虑下图:
    ![K-Means Clustering Algorithm](../Images/ed5e973486c1907df693a46c55b0d268.png)

从上图可以明显看出，线左侧的点靠近 K1 或蓝色质心，线右侧的点靠近黄色质心。让我们将它们涂成蓝色和黄色，以便清晰可见。

![K-Means Clustering Algorithm](../Images/769117f21ca0660b532457fd29a9eec9.png)

*   由于我们需要找到最近的聚类，所以我们将通过选择**一个新的质心**来重复这个过程。选择新的质心，我们会计算这些质心的重心，会发现新的质心如下:
    ![K-Means Clustering Algorithm](../Images/1a8481095a468d3f4a9e83d4ba637665.png)
*   接下来，我们将把每个数据点重新分配给新的质心。为此，我们将重复寻找中线的相同过程。中间值如下图所示:
    ![K-Means Clustering Algorithm](../Images/61c927e4b9bc179887e4d9d042e7cb6d.png)

从上图中，我们可以看到，一个黄色点在线的左侧，两个蓝色点在线的右侧。所以，这三个点将被分配给新的质心。

![K-Means Clustering Algorithm](../Images/f8ebb2c72920220546bff19ad36a899a.png)

由于重新分配已经发生，所以我们将再次进入第 4 步，即寻找新的质心或 K 点。

*   我们将通过寻找质心的重心来重复这个过程，这样新的质心将如下图所示:
    ![K-Means Clustering Algorithm](../Images/591f70d88dbcb064a7e68a5fad303072.png)
*   当我们得到新的质心时，我们将再次绘制中线并重新分配数据点。所以，图像会是:
    ![K-Means Clustering Algorithm](../Images/96a6da630d864b54e436a89de2726844.png)
*   我们可以在上图中看到；线的两边没有不相似的数据点，这意味着我们的模型形成了。考虑下图:
    ![K-Means Clustering Algorithm](../Images/94637ec941ecb3d21fc2311ab02c3333.png)

由于我们的模型已经准备好了，所以我们现在可以移除假设的质心，最后的两个簇将如下图所示:

![K-Means Clustering Algorithm](../Images/9ef91ab92b4d41b20dcd49bde2ee0fc0.png)

## K-means 聚类中“聚类的 K 个数”值如何选择？

K-means 聚类算法的性能取决于它所形成的高效聚类。但是选择最佳的集群数量是一项艰巨的任务。有一些不同的方法可以找到最佳的聚类数，但这里我们讨论的是找到聚类数或 k 值的最合适的方法。该方法如下:

### 肘法

肘部方法是寻找最佳聚类数的最流行方法之一。这种方法使用了 WCSS 值的概念。 **WCSS** 代表**聚类内的平方和**，它定义了一个聚类内的总变异。计算 WCSS 值的公式(针对 3 个集群)如下所示:

WCSS= ∑<sub>P<sub>i in Cluster1</sub></sub> distance(P<sub>i</sub> C<sub>1</sub>)<sup>2</sup> +∑<sub>P<sub>i in Cluster2</sub></sub>distance(P<sub>i</sub> C<sub>2</sub>)<sup>2</sup>+∑<sub>P<sub>i in CLuster3</sub></sub> distance(P<sub>i</sub> C<sub>3</sub>)<sup>2</sup>

在上面的 WCSS 公式中，

∑ <sub>集群 1 中的 P<sub>I</sub></sub>距离(P <sub>i</sub> C <sub>1</sub> ) <sup>2</sup> :是集群 1 中每个数据点与其质心之间距离的平方之和，其他两个术语也是如此。

为了测量数据点和质心之间的距离，我们可以使用任何方法，如欧几里德距离或曼哈顿距离。

要找到簇的最佳值，肘方法遵循以下步骤:

*   对于不同的 K 值(范围从 1 到 10)，它在给定的数据集上执行 K 均值聚类。
*   对于 K 的每个值，计算 WCSS 值。
*   在计算的 WCSS 值和聚类数 k 之间绘制一条曲线
*   弯曲的尖点或图中的一个点看起来像一条手臂，那么这个点被认为是 k 的最佳值。

由于该图显示了看起来像弯管的急弯，因此它被称为弯管法。肘部方法的图表如下图所示:

![K-Means Clustering Algorithm](../Images/5e42ce6466ed8bed458d2c8372aa576e.png)

#### 注意:我们可以选择与给定数据点相等的聚类数。如果我们选择与数据点相等的簇数，那么 WCSS 值为零，这将是图的终点。

## K-均值聚类算法的 Python 实现

在上面的章节中，我们已经讨论了 K-means 算法，现在让我们看看如何使用 [Python](https://www.javatpoint.com/python-tutorial) 来实现它。

在实现之前，让我们了解我们将在这里解决什么类型的问题。因此，我们有一个**商城 _ 客户**的数据集，这是访问商城并在那里消费的客户的数据。

在给定的数据集中，我们有 **Customer_Id、性别、年龄、年收入($)和支出分数**(这是计算出的一个客户在商场花了多少钱的值，值越多，他花的越多)。从这个数据集，我们需要计算一些模式，因为它是一种无监督的方法，所以我们不知道具体计算什么。

实施步骤如下:

*   **数据预处理**
*   **使用肘形法**找到最佳的簇数
*   **在训练数据集**上训练 K-means 算法
*   **可视化集群**

### 步骤 1:数据预处理步骤

第一步是数据预处理，正如我们在回归和分类的早期主题中所做的那样。但是对于聚类问题，它将不同于其他模型。我们来讨论一下:

*   **导入库**
    正如我们在前面的主题中所做的，首先，我们将为我们的模型导入库，这是数据预处理的一部分。代码如下:

```

# importing libraries  
import numpy as nm  
import matplotlib.pyplot as mtp  
import pandas as pd  

```

在上面的代码中，我们导入的 **[numpy](https://www.javatpoint.com/numpy-tutorial)** 用于执行数学计算， **matplotlib** 用于绘制图形，**pands**用于管理数据集。

*   **导入数据集:**
    接下来，我们将导入我们需要使用的数据集。这里，我们使用的是商城 _ 客户 _ 数据. csv 数据集。可以使用以下代码导入:

```

# Importing the dataset
dataset = pd.read_csv('Mall_Customers_data.csv')

```

通过执行上述代码行，我们将在 Spyder IDE 中获得数据集。数据集如下图所示:

![K-Means Clustering Algorithm](../Images/979a0416cddea0ade36069b7dbe570d5.png)

从上面的数据集，我们需要在其中找到一些模式。

*   **提取自变量**

这里我们不需要任何因变量进行数据预处理步骤，因为这是一个聚类问题，我们不知道要确定什么。所以我们将为特征矩阵添加一行代码。

```

x = dataset.iloc[:, [3, 4]].values

```

可以看到，我们只提取了 3 <sup>次</sup>和 4 <sup>次</sup>特征。这是因为我们需要一个 2d 图来可视化模型，而有些功能是不需要的，比如 customer_id。

### 步骤 2:使用肘形方法找到最佳的簇数

在第二步中，我们将尝试为我们的聚类问题找到最佳的聚类数。因此，如上所述，我们将为此目的使用肘关节方法。

正如我们所知，肘形方法使用 WCSS 概念，通过在 Y 轴上绘制 WCSS 值和在 X 轴上绘制簇的数量来绘制曲线图。所以我们要计算从 1 到 10 的不同 k 值的 WCSS 值。下面是它的代码:

```

#finding optimal number of clusters using the elbow method
from sklearn.cluster import KMeans
wcss_list= []  #Initializing the list for the values of WCSS

#Using for loop for iterations from 1 to 10.
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, init='k-means++', random_state= 42)
    kmeans.fit(x)
    wcss_list.append(kmeans.inertia_)
mtp.plot(range(1, 11), wcss_list)
mtp.title('The Elobw Method Graph')
mtp.xlabel('Number of clusters(k)')
mtp.ylabel('wcss_list')
mtp.show()

```

从上面的代码中我们可以看到，我们已经使用了 sklearn 的**KMeans**类。形成集群的集群库。

接下来，我们创建了 **wcss_list** 变量来初始化一个空列表，该列表用于包含针对范围从 1 到 10 的不同 k 值计算的 wcss 值。

之后，我们已经为迭代初始化了从 1 到 10 的不同 k 值的 for 循环；由于对于 Python 中的循环，排除了出站限制，因此它被视为 11 以包含第 10 个<sup>值。</sup>

代码的其余部分与我们在早期主题中所做的类似，因为我们已经将模型拟合到特征矩阵上，然后绘制了集群数量和 WCSS 之间的图表。

**输出:**执行完上面的代码后，我们会得到下面的输出:

![K-Means Clustering Algorithm](../Images/f59276340e94b5fc1f252902e5e64549.png)

从上面的图中，我们可以看到肘点在 **5。所以这里的簇数是 5。**

![K-Means Clustering Algorithm](../Images/b986f2510fb1a8d5a9d244a5e8768ac9.png)

### 步骤 3:在训练数据集上训练 K-means 算法

因为我们已经得到了聚类的数量，所以我们现在可以在数据集上训练模型。

为了训练模型，我们将使用与上面部分相同的两行代码，但是这里我们将使用 5，因为我们知道有 5 个集群需要形成。代码如下:

```

#training the K-means model on a dataset
kmeans = KMeans(n_clusters=5, init='k-means++', random_state= 42)
y_predict= kmeans.fit_predict(x)

```

第一行与上面创建 KMeans 类的对象相同。

在第二行代码中，我们创建了因变量 **y_predict** 来训练模型。

通过执行上面几行代码，我们将得到 y_predict 变量。我们可以在 Spyder IDE 的变量浏览器选项下**查看。我们现在可以将 y_predict 的值与原始数据集进行比较。请看下图:**

![K-Means Clustering Algorithm](../Images/300d7851e596bece01acb35eebb235ea.png)

从上图中，我们可以看出 CustomerID 1 属于一个集群

3(因为索引从 0 开始，所以 2 将被认为是 3)，2 属于簇 4，以此类推。

### 步骤 4:可视化集群

最后一步是可视化集群。由于我们的模型有 5 个集群，因此我们将逐个可视化每个集群。

为了可视化集群，我们将使用 matplotlib 的 mtp.scatter()函数使用散点图。

```

#visulaizing the clusters
mtp.scatter(x[y_predict == 0, 0], x[y_predict == 0, 1], s = 100, c = 'blue', label = 'Cluster 1') #for first cluster
mtp.scatter(x[y_predict == 1, 0], x[y_predict == 1, 1], s = 100, c = 'green', label = 'Cluster 2') #for second cluster
mtp.scatter(x[y_predict== 2, 0], x[y_predict == 2, 1], s = 100, c = 'red', label = 'Cluster 3') #for third cluster
mtp.scatter(x[y_predict == 3, 0], x[y_predict == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4') #for fourth cluster
mtp.scatter(x[y_predict == 4, 0], x[y_predict == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5') #for fifth cluster
mtp.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 300, c = 'yellow', label = 'Centroid') 
mtp.title('Clusters of customers')
mtp.xlabel('Annual Income (k$)')
mtp.ylabel('Spending Score (1-100)')
mtp.legend()
mtp.show()

```

在上面的代码行中，我们为每个集群编写了代码，范围从 1 到 5。mtp.scatter 的第一个坐标，即 x[y_predict == 0，0]，包含用于显示特征值矩阵的 x 值，y_predict 的范围为 0 到 1。

**输出:**

![K-Means Clustering Algorithm](../Images/8d028be38b3cc7174f0f02ef0993488f.png)

输出图像清楚地显示了具有不同颜色的五个不同集群。聚类是在数据集的两个参数之间形成的；客户年收入和支出。我们可以根据要求或选择改变颜色和标签。我们还可以从上面的模式中观察到一些点，如下所示:

*   **聚类 1** 显示平均工资和平均支出的客户，因此我们可以将这些客户分类为
*   集群 2 显示客户收入高但支出低，因此我们可以将其归类为**小心**。
*   集群 3 显示了低收入和低支出，因此它们可以归类为合理的。
*   集群 4 展示的是低收入高消费的客户，所以可以归类为**粗心**。
*   集群 5 显示了高收入和高支出的客户，因此他们可以被归类为目标客户，这些客户可以是商场老板最赚钱的客户。

* * *