# 熊猫小抄

> 原文：<https://www.javatpoint.com/pandas-cheat-sheet>

熊猫可以作为数据科学最重要的 Python 包。它有助于提供许多以更简单的方式处理数据的功能。它快速、灵活、富有表现力的数据结构旨在进行真实世界的数据分析。

熊猫小抄是熊猫基础知识的快速指南，你需要用 Python 开始争论你的数据。如果你想和熊猫一起开始你的数据科学之旅，你可以把它作为一个方便的参考来轻松处理数据。

这份小抄将指导你从数据结构到输入输出、选择、排序和排名等熊猫库的基础知识。

## 密钥和导入

我们在备忘单中使用以下简写:

*   **df:** 指任何熊猫数据帧对象。
*   **s:** 指任何熊猫系列对象。您可以使用以下导入开始:

### 导入数据

*   **pd.read_csv(文件名):**它从 csv 文件中读取数据。
*   **pd.read_table(文件名):**用于从分隔文本文件中读取数据。
*   **pd.read_excel(文件名):**它从 excel 文件中读取数据。
*   **pd.read_sql(query，connection _object) :** 它从一个 sql 表/数据库中读取数据。
*   **PD . read _ json(JSON _ string):**它从 JSON 格式的字符串、URL 或文件中读取数据。
*   **pd.read_html(url) :** 它解析一个 html URL、字符串或文件，并将表提取到一个数据帧列表中。
*   **pd.read_clipboard() :** 取剪贴板的内容，传递给 read_table()函数。
*   **pd。DataFrame(dict) :** 从 dict 中，列名的键、数据的值作为列表。

### 导出数据

*   **df.to_csv(文件名):**写入 csv 文件。
*   **df.to_excel(文件名):**写入 excel 文件。
*   **df.to_sql(table_name，connection_object):** 它写入一个 sql 表。
*   **df.to_json(文件名):**它以 json 格式写入文件。

### 创建测试对象

这对测试代码段很有用。

*   **pd。DataFrame(np.random.rand(7，18)):** 指 18 列 7 行随机浮动。
*   **pd。系列(我的列表):**它从一个可迭代的我的列表中创建一个系列。
*   **df . index = PD . date _ range(' 1940/1/20 '，periods=df.shape[0]):** 它添加日期索引。

### 查看/检查数据

*   **df.head(n):** 它返回数据帧的前 n 行。
*   **df.tail(n):** 它返回数据帧的最后 n 行。
*   **df.shape:** 返回行数和列数。
*   **df.info():** 它返回索引、数据类型和内存信息。
*   **s . value _ counts(drop na = False):**查看唯一值和计数。
*   **df.apply(pd。Series.value_counts):** 指所有列的唯一值和计数。

### 选择

*   **df[col1]:** 它返回标签列为 Series 的列。
*   **df[[col1，col2]]:** 它返回列作为新的数据帧。
*   **s.iloc[0]:** 按位置选择。
*   **s.loc['index_one']:** 按索引选择。
*   **df.iloc[0，]:** 返回第一行。
*   **df.iloc[0，0]:** 返回第一列的第一个元素。

### 数据清理

*   **df.columns = ['a '，' b '，' c']:** 它重命名列。
*   **pd.isnull():** 它检查空值并返回布尔数组。
*   **pd.notnull():** 与 pd.isnull()相反。
*   **df.dropna():** 它删除所有包含空值的行。
*   **df.dropna(轴= 1):** 它删除所有包含空值的列。
*   **df.dropna(axis=1，thresh=n):** 它丢弃所有小于 n 个非空值的行。
*   **df.fillna(x):** 它用 x 替换所有空值。
*   **s.fillna(s.mean()):** 它用平均值替换所有空值(平均值几乎可以用统计模块中的任何函数替换)。
*   **s.astype(float):** 它将序列的数据类型转换为 float。
*   **s.replace(1，' one'):** 它将所有等于 1 的值替换为“1”。
*   **s.replace([1，3]，['一'，'三']):** 它用'一'替换所有的 1，用'三'替换所有的 3。
*   **df . rename(columns =λx:x+1):**它重命名列的质量。
*   **df . rename(columns = { ' old _ name ':' new _ name ' }):**它由选择性重命名组成。
*   **df . set _ index(' column _ one '):**用于更改索引。
*   **df . rename(index =λx:x+1):**它重命名索引的质量。

### 筛选、排序和分组依据

*   **df[df[col] > 0.5]:** 返回列 col 大于 0.5 的行
*   **df[(df[col]>0.5)&(df[col]<0.7)]:**返回 0.7 > col > 0.5 的行
*   **df.sort_values(col1) :** 它按照 col1 的升序对值进行排序。
*   **df.sort_values(col2，升序=False) :** 它按 col2 降序对值进行排序。
*   **df.sort_values([col1，col2]，升序=[True，False]) :** 按 col1 升序、col2 降序对值进行排序。
*   **df.groupby(col1):** 为一列中的值返回 groupby 对象。
*   **df.groupby([col1，col2]) :** 为多个列中的值返回 groupby 对象。
*   **df.groupby(col1)[col2]) :** 返回 col2 中值的平均值，按 col1 中的值分组。
*   **df.pivot_table(index=col1，values=[col2，col3]，aggfunc=mean) :** 创建按 col1 分组的透视表，计算 col2 和 col3 的平均值。
*   **df.groupby(col1)。agg(np.mean) :** 它计算每个唯一 col1 组的所有列的平均值。
*   **df.apply(np.mean) :** 它的任务是将函数 np.mean()应用于每一列。
*   **nf.apply(np.max，axis=1) :** 它的任务是在每行上应用函数 np.max()。

### 加入/合并

*   **df1.append(df2):** 它的任务是将 df1 中的行添加到 df2 的末尾(列应该相同)。
*   **pd.concat([df1，df2]，axis=1):** 它的任务是将 df1 中的列添加到 df2 的末尾(行应该相同)。
*   **df1.join(df2，on=col1，how='inner'):** SQL 样式将 df1 中的列与 df2 中的列连接起来，其中 col 的行具有相同的值，“how”可以是“left”、“right”、“outer”、“inner”。

### 统计数字

统计功能可应用于系列，如下所示:

*   **df . description():**返回数值列的汇总统计。
*   **df.mean() :** 返回所有列的平均值。
*   **df.corr():** 返回数据框中各列之间的相关性。
*   **df.count():** 它返回每个数据帧列中所有非空值的计数。
*   **df.max():** 它返回每个列的最高值。
*   **df.min():** 它返回每个列的最小值。
*   **df . middle():**它返回每个列的中值。
*   **df.std():** 返回每一列的标准差。

* * *