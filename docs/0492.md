# 无监督人工神经网络算法和技术

> 原文:[https://www . javatpoint . com/unsupervised-ANNs-算法和技术](https://www.javatpoint.com/unsupervised-anns-algorithms-and-techniques)

无监督人工神经网络中使用的技术和算法包括自组织映射、受限玻尔兹曼机器、自动编码器等。

## 自组织地图:

自组织映射是一种基本类型的人工神经网络，其发展依赖于无监督的学习过程和利用数据之间的相似性。自组织地图的生物学灵感来自通过神经元自组织学习的拓扑计算地图。这一动机源于人类大脑中不同的输入是如何组织成地形图的。与有监督的人工神经网络不同，自组织映射由没有隐藏层的输入和输出神经元组成，并且以只有一个输出神经元可以被激活的方式开发。

它总结了竞争学习，一个所有输出神经元相互竞争的过程。这种比赛的获胜者被解雇，被称为获胜的神经元。通过搜索具有表征其在输入空间中的坐标的权重集的输出神经元，一种理解输出神经元之间竞争的方法是通过计算判别函数值，典型地是它们和输入中的当前样本的分量向量之间的欧几里德距离。从位于网格节点的一组神经元中选择神经元，转化成许多输入模式，组织它们自己，并在网格结构上形成地形图。当被提供输入信号时，神经元的坐标显示了输入结构中的统计表示。顾名思义，自组织地图提供了一种地形图，它在内部描绘了所提供输入的输入模式中的统计特征。

初始化、竞争、适应和合作是神经元自组织的重要组成部分。在初始阶段，随机选择的小值最初被分配为输出神经元的权重。然后，输出神经元将通过比较判别函数值来相互竞争。限制判别函数值的输出神经元被选择为获胜者，并更新其权重，使其更接近当前观察值。获胜神经元与其邻域(以半径为特征)之间存在合作，因为不仅其权重被更新，而且预定义邻域的权重也被更新，获胜神经元对输入向量的更新相对较高。这种合作受到人脑中兴奋神经元群之间横向联系的启发。

相邻神经元接收的更新权重是它们之间的横向距离和获胜神经元的函数，最近和最远的神经元分别接受最高和最低的权重更新。权重被更新，以便对数据进行有效的无监督分类。这背后的数据是需要提高与训练输入最匹配的单元之间的相似性。通常被称为最佳匹配单元的无向图形模型，以及与输入相邻的图形模型。自组织映射算法中相关的五个阶段是采样、初始化、找到权重向量与输入向量最匹配的神经元、使用给定的等式更新获胜神经元和邻域中的神经元的权重，以及返回采样阶段，直到 ni(输入数)级数可以在特征映射中实现。Kohonen 网络是一种自组织地图。

**【wji = TJ I(x)(t)(Xi-wji)**

![Unsupervised ANNs Algorithms and Techniques](../Images/b332c1ace7877f27e347ceaa02ab00ca.png)

图中显示了科霍宁网络要素图。自组织映射人工神经网络通常用于聚类和类脑特征映射。它们适用于探索性数据、统计、生物医学、金融、工业和控制分析领域。

## 受限玻尔兹曼机器:

玻尔兹曼机器(BMs)已经被引入作为**假设的**处理单元的双向连接网络，其可以被解释为神经网络模型。玻尔兹曼机器可用于根据分布样本学习未知概率分布的重要方面。一般来说，这个学习过程是困难和繁琐的。然而，学习问题可以通过对网络拓扑施加限制来简化，这导致我们使用受限的玻尔兹曼机器。受限 BM 是表示概率分布的生成模型。给定一些观察，学习 BM 的训练数据意味着改变 BM 参数，使得 BM 表示的概率分布适合训练数据。玻尔兹曼机器由两种类型的单元组成，可见和隐藏的神经元，它们可以排列成两层。可见单元建立了主要层，并对应于观察的组成部分。例如，数字图像的每个像素有一个可见单位。在隐藏单元中，模型依赖位于观察的组件之间。例如，图像中像素之间的相关性。它们可以被视为非线性元素指示器。

![Unsupervised ANNs Algorithms and Techniques](../Images/1a1ad45e3bf5fd97857e4bf5e5e6a3b4.png)

玻尔兹曼机器也可以被视为特定的图形模型，更准确地说是无向图形模型，也称为马尔可夫随机场。将 BMs 嵌入到概率图形模型的结构中，可以快速获得大量的假设结果和完善的算法。计算无向模型的概率或其用于推断的梯度通常在计算上是全面的。因此，基于采样的技术被用来估计概率及其梯度。从无向图形模型中采样通常并不简单，但是从 RBMs **马尔可夫链蒙特卡罗** (MCMC)技术可以很容易地以**吉布斯采样**的形式应用。

![Unsupervised ANNs Algorithms and Techniques](../Images/b7ab07421799b569853af234fc0fe65d.png)

受限玻尔兹曼机(RBM)是一个马尔可夫随机场(MRF)，与给定图中所示的两个无向图相关。它包括 **x** 可见单位 **V = (V1，…，Vx)** 显示数据和 n 个隐藏单位 **H = (H1，…，Hn)** 捕捉观测变量。在二元 RBMs 中，我们关注的是随机变量 **(V，H)** 取值 **(V，H)∑{ 0，1} <sup>x+n</sup>** 以及吉布斯分布**给出的模型下的联合概率分布【P(V，H) = 1/z <sup>e-E(v，h)</sup>** 具有能量函数。

![Unsupervised ANNs Algorithms and Techniques](../Images/7a429cbadabe0bb14337fc703faedd4f.png)

对于所有**I∞{ 1，...，n}** 和**j∞{ 1，...，x}，Wij** 是连接到单位之间的边缘的实值权重 **Vj** 和 **Hi、**和 **Bj** 和 **Ci** 分别是连接到可见的 **jth** 和带有隐藏变量的**的实值偏差项。**

RBM 图只有隐藏变量层和可见变量层之间的关联，而没有相似层的两个变量之间的关联。就概率而言，它意味着隐藏变量是独立的，给定可见变量的状态，反之亦然。

**自动编码器：**

自动编码器是一种神经网络，准备尝试将其输入复制到输出。在内部，它有一个隐藏层，描述用于表示输入的代码。

自动编码器是具有不对称结构的人工神经网络，其中中间层表示输入数据的编码。Autoencoder 准备将其输入重建到输出层，同时确认某些限制，这些限制使其无法随网络复制数据。虽然自动编码器这个术语现在最流行，但它们也被称为自动联想神经网络、空竹网络和复制神经网络。

![Unsupervised ANNs Algorithms and Techniques](../Images/7961de142b2da5439a65cabaa7b4ec4c.png)

自动编码器的基本结构如下图所示。它包含一个输入 **p** ，通过编码器映射到编码 **b** 上，表示为函数 **F** 。该编码被映射为利用解码器的再创造 **r** ，表示为功能 **Z** 。

这种结构被前馈神经网络捕获。由于目标是在输出层再现输入数据，因此 **p** 和 **r** 都具有相似的维度。 **p** 可以有更高的尺寸或更低的尺寸，这取决于所需的属性。自动编码器也可以根据需要具有不同的层，通常对称地放置在编码器和解码器中。这样的神经架构可以在下图中看到。

![Unsupervised ANNs Algorithms and Techniques](../Images/af57922f5ee42005477fd275f07c2106.png)

* * *