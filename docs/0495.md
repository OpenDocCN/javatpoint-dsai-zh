# 玻尔兹曼机器

> 原文:[https://www.javatpoint.com/boltzmann-machines](https://www.javatpoint.com/boltzmann-machines)

玻尔兹曼机器指的是一个由一致关联的神经元样结构组成的联合体，这些神经元样结构做出关于是开启还是关闭的假设决定。玻尔兹曼机器是由著名科学家**杰弗里·辛顿**和**特里·塞诺斯基**于 1985 年发明的。玻尔兹曼机器有一个基本的学习算法，允许他们找到代表训练数据中复杂规律的令人兴奋的特征。在具有各层特征检测器的网络中，学习算法通常很慢，但在具有单层特征检测器的“**受限玻尔兹曼机器**”中，学习算法很快。通过包括玻尔兹曼机器，利用一个的特征激活作为下一个的训练数据，可以有效地适应许多隐藏层。

玻尔兹曼机器被用来解决两个不同的计算问题。首先，**对于搜索问题**，关联上的权重是固定的，并且用于表示成本函数。玻尔兹曼机器的随机动力学允许它对具有成本函数最小值的二进制状态向量进行采样。其次，对于学习问题，玻尔兹曼机器已经指出了一组二进制数据向量，这必须找出如何高概率地生成这些向量。为了解决这个问题，它必须发现关联上的权重，以便相对于其他可能的二进制向量，数据向量具有成本函数的最小值。为了解决学习问题，玻尔兹曼机器对其权重进行了大量的小更新，每次更新都希望它们能够解决广泛的搜索问题。

## 玻尔兹曼机器的随机动力学；

当给单元 **i** 一个更新其二进制状态的机会时，它首先计算其绝对输入， **p <sub>i</sub>** ，这是其自身偏差、 **q <sub>i</sub>** 以及来自其他活动单元的关联权重的总和:

**P <sub>i</sub> = q <sub>i</sub> +？<sub>j</sub>m<sub>j</sub>w<sub>ij</sub>T11】**

哪里，

**w <sub>ij</sub>** =是 **i** 与 **j** 关联上的权重，当单元 **j** 开启时，**m<sub>j</sub>T11】为 **1** 。单元 **i** 以逻辑函数给出的概率打开:**

![Boltzmann Machines](../Images/03a91bb500701843b6c02beb44e90465.png)

如果单元以不依赖于其总输入的任何顺序连续更新，网络将最终达到玻尔兹曼分布(也称为平衡或平稳分布)，其中给定状态向量 **k** 的概率仅由该状态向量与所有可能的二进制状态向量的能量相比的“能量”来确定:

![Boltzmann Machines](../Images/52bdf965c377e3809da857d2ad3efc73.png)

与霍普菲尔德网络一样，状态向量 **k** 的能量定义为

![Boltzmann Machines](../Images/d7926e0ad73364e5a5e95df51a1005f2.png)

其中，s<sub>I</sub>T2【k 是由状态向量 **k** 指定给单位 **i** 的二进制状态。如果选择关联上的权重，使得状态向量的能量代表那些状态向量的成本，玻尔兹曼机器的随机动力学可以被看作是一种在寻找低成本解决方案时摆脱不良局部最优的方法。单元 **i** 、 **p <sub>i</sub>** 的总输入，代表了依赖于单元是关还是开的能量差异，单元 **i** 有时打开的方式，即使 **p <sub>i</sub>** 为负，也意味着能量在搜索过程中偶尔会增加，因此允许搜索跳过能量障碍。搜索可以通过使用模拟退火来升级。它将所有的重量和能量缩小了一个因子 **T** ，这相当于一个物理网络的温度。通过将 **T** 从相当大的初始值最小化到小的最终值，有可能受益于高温下的快速平衡，并且仍然具有最终平衡分布，这使得最小解比高成本解更有可能。在零温度下，更新规则变得确定，玻尔兹曼机器转换成霍普菲尔德网络。

**不同类型的玻尔兹曼机**

学习规则可以容纳更复杂的能量函数。例如，二次能量函数可以被具有共同术语**s<sub>I</sub>s<sub>j</sub>s<sub>k</sub>w<sub>ijk</sub>T9】的能量函数代替。用于更新规则的总输入 **i** 必须替换为**

![Boltzmann Machines](../Images/e6895ec3488dcd9f431527c32a1ca997.png)

学习规则的显著变化是 s <sub>i</sub> s <sub>j</sub> 被 s <sub>i</sub> s <sub>j</sub> s <sub>k</sub> 代替。玻尔兹曼机器模拟数据向量的分散。然而，有一个基本的扩展，用于模拟条件分布的“条件玻尔兹曼机”。可见单元和隐藏单元的显著区别在于采样(s <sub>i</sub> s <sub>j</sub> 数据时，可见单元被箝位，隐藏单元可能没有。如果采样时夹紧了可见单元的一个子集)(s <sub>i</sub> s <sub>j</sub> ) <sub>型号</sub>，则该子集作为“输入”单元，其余可见单元作为“输出”单元。

### 学习的速度

在具有各种隐藏层的玻尔兹曼机器中，学习通常非常慢，因为巨大的网络可能需要相当长的时间来接近它们的平衡分布，尤其是当权重巨大并且平衡分布高度多峰时。当可以从平衡分布中获取样本时，学习信号非常嘈杂，因为它是两个采样期望之间的差异。这些问题可以通过限制网络、简化学习算法和一次学习一个隐藏层来克服。

### 受限玻尔兹曼机:

1986 年**斯摩棱斯基**发明的**受限玻尔兹曼机**。它由一层可见单元和一层隐藏单元组成，没有可见-可见或隐藏-隐藏关联。有了这些限制，在给定一个可见向量的情况下，隐藏单元暂时是自治的，因此可以在一个并行步骤中获得无偏样本形式(s <sub>i</sub> s <sub>j</sub> ) <sub>数据</sub>。为了采样表单(s <sub>i</sub> s <sub>j</sub> ) <sub>模型</sub>仍然需要不同的迭代，在并行恢复所有隐藏单元和并行恢复所有可见单元之间进行替换。然而，如果将(s <sub>i</sub> s <sub>j</sub> ) <sub>模型</sub>替换为(s <sub>i</sub> s <sub>j</sub> ) <sub>重构</sub>，则学习仍然可以很好地发挥作用，如下所示:

从可见单元上的数据向量开始，并行恢复所有隐藏单元。

并行更新所有可见单元以获得重建。

再次更新所有隐藏的单位。

* * *