# 数据挖掘中的数据清洗

> 原文:[https://www.javatpoint.com/data-cleaning-in-data-mining](https://www.javatpoint.com/data-cleaning-in-data-mining)

数据清洗是数据挖掘中的一个关键过程。它在模型构建中起着重要的作用。数据清理可以看作是需要的过程，但大家往往忽略了。数据质量是质量信息管理的主要问题。数据质量问题出现在信息系统的任何地方。这些问题通过数据清理得到解决。

数据清理是修复或删除数据集中不正确、损坏、格式不正确、重复或不完整的数据。如果数据不正确，结果和算法就不可靠，即使它们看起来是正确的。当组合多个数据源时，有很多数据被复制或错误标记的机会。

通常，数据清理可以减少错误并提高数据质量。纠正数据中的错误和消除不良记录可能是一个耗时且繁琐的过程，但不可忽视。数据挖掘是数据清洗的关键技术。数据挖掘是一种从数据中发现有趣信息的技术。数据质量挖掘是应用数据挖掘技术来识别和恢复大型数据库中的数据质量问题的一种新方法。数据挖掘自动从数据集合中提取隐藏的和内在的信息。数据挖掘有各种适合数据清理的技术。

理解和纠正数据质量对于获得准确的最终分析至关重要。需要准备好数据来发现关键模式。数据挖掘被认为是探索性的。数据挖掘中的数据清理允许用户在进行业务分析和洞察之前发现不准确或不完整的数据。

在大多数情况下，数据挖掘中的数据清理可能是一个费力的过程，通常需要信息技术资源来帮助评估数据的初始步骤，因为数据挖掘之前的数据清理非常耗时。但是，如果没有适当的数据质量，您的最终分析将会不准确，或者您可能会得出错误的结论。

### 数据清理的步骤

虽然用于数据清理的技术可能因公司存储的数据类型而异，但您可以按照以下基本步骤清理数据，例如:

**1。删除重复或不相关的观察**

从数据集中删除不需要的观察，包括重复的观察或不相关的观察。重复的观察最常发生在数据收集期间。当您组合来自多个地方的数据集、刮擦数据或从客户端或多个部门接收数据时，有机会创建重复数据。重复数据消除是此过程中需要考虑的最大领域之一。不相关的观察是指当你注意到与你试图分析的具体问题不相符的观察时。

例如，如果您想分析有关千禧一代客户的数据，但您的数据集包括老一辈客户，您可以删除那些不相关的观察结果。这可以提高分析效率，最大限度地减少对主要目标的干扰，并创建更易于管理和执行的数据集。

**2。修复结构错误**

结构性错误是当您测量或传输数据时，注意到奇怪的命名约定、错别字或不正确的大写。这些不一致会导致错误标记的类别或类。例如，您可能会在任何表中发现“不适用”和“不适用”，但它们应该在同一类别中进行分析。

**3。过滤不想要的异常值**

通常，会有一次性的观察结果，一眼看去，它们似乎不符合您正在分析的数据。如果您有合法的理由删除异常值，如不正确的数据输入，这样做将有助于您正在处理的数据的性能。

然而，有时，异常值的出现会证明你正在研究的理论。仅仅因为一个异常值的存在并不意味着它是不正确的。需要这一步来确定该号码的有效性。如果一个异常值被证明与分析无关或者是一个错误，考虑删除它。

**4。处理缺失数据**

您不能忽略丢失的数据，因为许多算法不接受丢失的值。有几种方法可以处理丢失的数据。两者都不是最优的，但都可以考虑，例如:

*   您可以删除缺少值的观察值，但这会删除或丢失信息，因此在删除之前要小心。
*   您可以根据其他观察结果输入缺失值；同样，有可能丢失数据的完整性，因为您可能是根据假设而不是实际观察来操作的。
*   您可能会改变如何使用数据来有效地导航空值。

**5。验证和质量保证**

在数据清理过程结束时，作为基本验证的一部分，您应该能够回答这些问题，例如:

*   数据有意义吗？
*   数据是否遵循其字段的适当规则？
*   它是否证明或否定了你的工作理论，或者揭示了什么？
*   你能在数据中找到趋势来帮助你的下一个理论吗？
*   如果不是，是因为数据质量问题吗？

由于数据不正确或有噪音，错误的结论可能会影响糟糕的商业战略和决策。错误的结论可能会导致报告会议中的尴尬时刻，当你意识到你的数据经不起研究时。在你到达那里之前，在你的组织中创造一种高质量数据的文化是很重要的。为此，您应该记录可能用于创建此策略的工具。

### 数据清理的方法

有许多数据清理方法可以运行数据。这些方法描述如下:

![Data Cleaning in Data Mining](../Images/dcc4d601f8e11f6da793483f9591755b.png)

1.  **忽略元组:**这个方法不太可行，因为它只有在元组有几个属性是有缺失值的时候才会用到。
2.  **填充缺失值:**这种做法也不是很有效，也不可行。此外，这可能是一种耗时的方法。在这种方法中，必须填写缺失的值。这通常是手动完成的，但也可以通过属性均值或使用最大可能值来完成。
3.  **宁滨法:**这种做法很简单易懂。排序数据的平滑是使用其周围的值来完成的。然后，数据被分成大小相等的几个部分。之后，执行不同的方法来完成任务。
4.  **回归:**借助使用回归函数使数据平滑。回归可以是线性的或多重的。线性回归只有一个自变量，多元回归有多个自变量。
5.  **聚类:**该方法主要对组进行操作。聚类将数据分组到一个聚类中。然后，在聚类的帮助下检测异常值。接下来，相似的值被排列成“组”或“簇”。

### 数据清理过程

以下步骤显示了数据挖掘中数据清理的过程。

1.  **监控错误:**记录最容易出错的地方是否合适。这将使确定和稳定虚假或腐败信息变得更加容易。在将另一种可能的替代方案与已建立的管理软件集成时，信息尤其必要。
2.  **规范挖掘流程:**规范插入点辅助，减少口是心非的几率。
3.  **验证数据准确性:**分析并投入数据工具，实时清理记录。工具使用人工智能来更好地检查正确性。
4.  **清除重复数据:**确定重复数据以节省分析数据的时间。通过分析和投资单独的数据擦除工具，可以避免频繁尝试相同的数据，这些工具可以大量分析粗略的数据，并使操作自动化。
5.  **数据研究:**在此活动之前，必须对我们的数据进行标准化、验证和清理，以寻找重复数据。有许多第三方来源，这些经批准的&授权方来源可以直接从我们的数据库中获取信息。它们帮助我们清理和编译数据，以确保商业决策的完整性、准确性和可靠性。
6.  **与团队沟通:**保持团队循环将有助于开发和加强客户，并向潜在客户发送更有针对性的数据。

### 数据清洗在数据挖掘中的应用

以下是数据挖掘中数据清理的一些用法，例如:

![Data Cleaning in Data Mining](../Images/0b9405e81fae2e68a9a820eabe1075a3.png)

*   **数据集成:**由于在低质量的数据中很难保证质量，数据集成对于解决这个问题有着重要的作用。数据集成是将来自不同数据集的数据组合成单个数据集的过程。这个过程使用数据清理工具来确保嵌入的数据集在移动到最终目的地之前是标准化和格式化的。
*   **数据迁移:**数据迁移是将一个文件从一个系统移动到另一个系统，从一种格式移动到另一种格式，或者从一个应用程序移动到另一个应用程序的过程。当数据在移动时，重要的是保持其质量、安全性和一致性，以确保生成的数据具有正确的格式和结构，并且在目的地没有任何瑕疵。
*   **数据转换:**数据上传到目的地之前，需要进行转换。这只有通过数据清理才能实现，数据清理考虑了格式化、结构化等系统标准。数据转换过程通常包括在进一步分析之前使用规则和过滤器。数据转换是大多数数据集成和数据管理过程中不可或缺的一部分。数据清理工具有助于使用系统的内置转换来清理数据。
*   **ETL 流程中的数据调试:**数据清理对于在提取、转换和加载(ETL)期间准备数据以进行报告和分析至关重要。数据清理确保只有高质量的数据用于决策和分析。

例如，一家零售公司从各种来源(如客户关系管理或企业资源规划系统)接收包含错误信息或重复数据的数据。一个好的数据调试工具会检测到数据中的不一致并纠正它们。清除的数据将被转换为标准格式并上传到目标数据库。

### 数据清洗的特点

数据清理是强制性的，以保证业务数据的准确性、完整性和安全性。根据数据的质量或特征，这些数据的质量可能会有所不同。以下是数据挖掘中数据清理的要点:

![Data Cleaning in Data Mining](../Images/55a6e3841a3c48c098ea330c123836dd.png)

*   **准确性:**构成业务内数据库的所有数据必须高度准确。证实其准确性的一种方法是将它们与不同的来源进行比较。如果没有找到源或源有错误，存储的信息也会有同样的问题。
*   **相干性:**数据之间必须是一致的，所以你可以确定一个个体或身体的信息在所使用的不同存储形式中是相同的。
*   **有效性:**存储的数据必须有一定的规定或既定的限制。同样，必须核实信息以证实其真实性。
*   **一致性:**组成数据库的数据必须具有相同的单位或值。这是执行数据清理过程的一个重要方面，因为它不会增加过程的复杂性。
*   **数据验证:**必须随时验证流程，包括程序的适当性和有效性。所述验证通过研究、设计和验证阶段的各种坚持来进行。在数据应用于一定数量的更改后，缺点往往很明显。
*   **清理数据回流:**在消除质量问题之后，已经清理的数据必须被那些不在原始源中的数据所替换，这样遗留应用程序就获得了这些好处，避免了应用程序在之后进行数据清理的动作。

### 数据挖掘中的数据清理工具

如果您对自己清理数据没有信心，或者没有时间清理所有数据集，数据清理工具会非常有帮助。你可能需要投资这些工具，但这是值得的。市场上有很多数据清理工具。以下是一些排名靠前的数据清理工具，例如:

1.  OpenRefine
2.  特里法塔牧马人
3.  雄鸭
4.  数据阶梯
5.  数据清理器
6.  Cloudingo
7.  具体化
8.  IBM 信息圈质量阶段
9.  TIBCO 净度
10.  辛普特

### 数据清理的好处

拥有干净的数据将最终提高整体工作效率，并为您的决策提供最高质量的信息。以下是数据挖掘中数据清理的一些主要好处，例如:

*   当有多个数据源时消除错误。
*   更少的错误会让客户更快乐，让员工不那么沮丧。
*   能够映射不同的功能和数据的用途。
*   监控错误并更好地报告，以了解错误来自哪里，从而更容易为未来的应用程序修复不正确或损坏的数据。
*   使用工具进行数据清理将有助于更高效的业务实践和更快的决策制定。

* * *