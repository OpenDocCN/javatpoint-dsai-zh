# 多元线性回归

> 原文:[https://www . javatpoint . com/机器学习中的多元线性回归](https://www.javatpoint.com/multiple-linear-regression-in-machine-learning)

在前一个主题中，我们已经了解了简单线性回归，其中使用单个独立/预测(X)变量来建模响应变量(Y)。但是可能存在响应变量受一个以上预测变量影响的各种情况；对于这种情况，使用多元线性回归算法。

此外，多元线性回归是简单线性回归的扩展，因为它需要多个预测变量来预测响应变量。我们可以将其定义为:

> *多元线性回归是对单个因变量和多个自变量之间的线性关系进行建模的重要回归算法之一。*

**示例:**

基于汽车发动机尺寸和气缸数量的一氧化碳 <sub>2</sub> 排放预测。

**关于 MLR 的一些要点:**

*   对于多元线性回归，因变量或目标变量(Y)必须是连续/实变量，但预测变量或自变量可以是连续或分类形式。
*   每个特征变量必须用因变量来模拟线性关系。
*   MLR 试图通过多维数据点空间拟合一条回归线。

### 多层线性回归方程:

多元线性回归中，目标变量(Y)是多个预测变量 x <sub>1</sub> 、x <sub>2</sub> 、x <sub>3</sub> 的线性组合，...，x <sub>n</sub> 。因为它是简单线性回归的增强，所以同样适用于多元线性回归方程，方程变成:

```

Y= b0+b1x1+ b2x2+ b3x3+...... bnxn       ............... (a)

```

哪里，

**Y=输出/响应变量**

**b <sub>0</sub> ，b <sub>1</sub> ，b <sub>2</sub> ，b <sub>3</sub> ，b <sub>n</sub> ....=模型的系数。**

**x <sub>1</sub> ，x <sub>2</sub> ，x <sub>3</sub> ，x <sub>4</sub> ，...=各种独立/特征变量**

### 多元线性回归的假设:

*   目标变量和预测变量之间应该存在**线性关系**。
*   回归残差必须是**正态分布**。
*   MLR 假设数据中很少或没有多重共线性(自变量之间的相关性)。

### 使用 Python 实现多元线性回归模型；

要使用 Python 实现 MLR，我们有以下问题:

**问题描述:**

我们有一个 50 家初创公司的数据集。该数据集包含五个主要信息: **R & D 支出、管理支出、营销支出、州和财政年度利润**。我们的目标是创建一个模型，可以很容易地确定哪个公司的利润最大，哪个是影响公司利润最大的因素。

因为我们需要找到利润，所以它是因变量，其他四个变量是自变量。以下是部署 MLR 模型的主要步骤:

1.  **数据预处理步骤**
2.  **将 MLR 模型拟合到训练集**
3.  **预测测试集的结果**

**步骤-1:数据预处理步骤:**

第一步是[数据预处理](data-preprocessing-machine-learning)，我们已经在本教程中讨论过了。该过程包含以下步骤:

*   **导入库:**首先我们将导入有助于构建模型的库。下面是它的代码:

```

# importing libraries
import numpy as nm
import matplotlib.pyplot as mtp
import pandas as pd

```

*   **导入数据集:**现在我们将导入包含所有变量的数据集(50 _ CompList)。下面是它的代码:

```

#importing datasets
data_set= pd.read_csv('50_CompList.csv')

```

**输出:**我们将获得如下数据集:

![Multiple Linear Regression](../Images/962f9934fcd368e6a9a55a6e05ccb801.png)

在上面的输出中，我们可以清楚地看到有五个变量，其中四个变量是连续的，一个是分类变量。

*   **提取因变量和自变量:**

```

#Extracting Independent and dependent Variable
x= data_set.iloc[:, :-1].values
y= data_set.iloc[:, 4].values

```

**输出:**

**输出[5]:**

```
array([[165349.2, 136897.8, 471784.1, 'New York'],
       [162597.7, 151377.59, 443898.53, 'California'],
       [153441.51, 101145.55, 407934.54, 'Florida'],
       [144372.41, 118671.85, 383199.62, 'New York'],
       [142107.34, 91391.77, 366168.42, 'Florida'],
       [131876.9, 99814.71, 362861.36, 'New York'],
       [134615.46, 147198.87, 127716.82, 'California'],
       [130298.13, 145530.06, 323876.68, 'Florida'],
       [120542.52, 148718.95, 311613.29, 'New York'],
       [123334.88, 108679.17, 304981.62, 'California'],
       [101913.08, 110594.11, 229160.95, 'Florida'],
       [100671.96, 91790.61, 249744.55, 'California'],
       [93863.75, 127320.38, 249839.44, 'Florida'],
       [91992.39, 135495.07, 252664.93, 'California'],
       [119943.24, 156547.42, 256512.92, 'Florida'],
       [114523.61, 122616.84, 261776.23, 'New York'],
       [78013.11, 121597.55, 264346.06, 'California'],
       [94657.16, 145077.58, 282574.31, 'New York'],
       [91749.16, 114175.79, 294919.57, 'Florida'],
       [86419.7, 153514.11, 0.0, 'New York'],
       [76253.86, 113867.3, 298664.47, 'California'],
       [78389.47, 153773.43, 299737.29, 'New York'],
       [73994.56, 122782.75, 303319.26, 'Florida'],
       [67532.53, 105751.03, 304768.73, 'Florida'],
       [77044.01, 99281.34, 140574.81, 'New York'],
       [64664.71, 139553.16, 137962.62, 'California'],
       [75328.87, 144135.98, 134050.07, 'Florida'],
       [72107.6, 127864.55, 353183.81, 'New York'],
       [66051.52, 182645.56, 118148.2, 'Florida'],
       [65605.48, 153032.06, 107138.38, 'New York'],
       [61994.48, 115641.28, 91131.24, 'Florida'],
       [61136.38, 152701.92, 88218.23, 'New York'],
       [63408.86, 129219.61, 46085.25, 'California'],
       [55493.95, 103057.49, 214634.81, 'Florida'],
       [46426.07, 157693.92, 210797.67, 'California'],
       [46014.02, 85047.44, 205517.64, 'New York'],
       [28663.76, 127056.21, 201126.82, 'Florida'],
       [44069.95, 51283.14, 197029.42, 'California'],
       [20229.59, 65947.93, 185265.1, 'New York'],
       [38558.51, 82982.09, 174999.3, 'California'],
       [28754.33, 118546.05, 172795.67, 'California'],
       [27892.92, 84710.77, 164470.71, 'Florida'],
       [23640.93, 96189.63, 148001.11, 'California'],
       [15505.73, 127382.3, 35534.17, 'New York'],
       [22177.74, 154806.14, 28334.72, 'California'],
       [1000.23, 124153.04, 1903.93, 'New York'],
       [1315.46, 115816.21, 297114.46, 'Florida'],
       [0.0, 135426.92, 0.0, 'California'],
       [542.05, 51743.15, 0.0, 'New York'],
       [0.0, 116983.8, 45173.06, 'California']], dtype=object)

```

正如我们在上面的输出中看到的，最后一列包含分类变量，这些变量不适合直接用于拟合模型。所以我们需要对这个变量进行编码。

**对虚拟变量进行编码:**

因为我们有一个分类变量(状态)，它不能直接应用于模型，所以我们将对它进行编码。为了将分类变量编码成数字，我们将使用**标签编码器**类。但是这是不够的，因为它仍然有一些关系顺序，这可能会创建一个错误的模型。所以为了消除这个问题，我们将使用 **OneHotEncoder** ，它将创建虚拟变量。下面是它的代码:

```

#Catgorical data
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
labelencoder_x= LabelEncoder()
x[:, 3]= labelencoder_x.fit_transform(x[:,3])
onehotencoder= OneHotEncoder(categorical_features= [3])  
x= onehotencoder.fit_transform(x).toarray()

```

这里我们只编码一个自变量，它是状态，因为其他变量是连续的。

**输出:**

![Multiple Linear Regression](../Images/63cf988c564f905279d006b1b56a61ad.png)

正如我们在上面的输出中所看到的，状态列已经被转换成虚拟变量(0 和 1)。**这里每个虚拟变量列对应一个状态**。我们可以通过与原始数据集进行比较来进行检查。第一列对应**加利福尼亚州**，第二列对应**佛罗里达州**，第三列对应**纽约州**。

#### 注意:我们不应该同时使用所有的哑变量，所以必须比哑变量总数少 1，否则会造成哑变量陷阱。

*   现在，我们编写一行代码只是为了避免虚拟变量陷阱:

```

#avoiding the dummy variable trap:
x = x[:, 1:]

```

如果我们不删除第一个虚拟变量，那么它可能会在模型中引入多重共线性。

![Multiple Linear Regression](../Images/0b46769446694fa80cdc01f3d4fb39eb.png)

正如我们在上面的输出图像中看到的，第一列已经被删除。

*   现在我们将数据集分成训练集和测试集。这方面的代码如下:

```

# Splitting the dataset into training and test set.
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.2, random_state=0)

```

上面的代码将把我们的数据集分成训练集和测试集。

**输出:**以上代码将数据集拆分为训练集和测试集。您可以通过单击 Spyder IDE 中给出的变量资源管理器选项来检查输出。测试集和训练集如下图所示:

**测试集:**

![Multiple Linear Regression](../Images/5295ef3af162d17a3b4f92c684d87c27.png)

**训练集:**

![Multiple Linear Regression](../Images/e6db41f33b28b7e3e25dc1b6b428b4b1.png)

#### 注意:在 MLR 中，我们不会进行特征缩放，因为它是由库负责的，所以我们不需要手动进行。

### 第二步:将我们的多层线性回归模型与训练集相匹配:

现在，为了提供训练，我们已经准备好了数据集，这意味着我们将使我们的回归模型适合训练集。这将类似于我们在[简单线性回归](simple-linear-regression-in-machine-learning)模型中所做的。这方面的代码是:

```

#Fitting the MLR model to the training set:
from sklearn.linear_model import LinearRegression
regressor= LinearRegression()
regressor.fit(x_train, y_train)

```

**输出:**

```
Out[9]: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)

```

现在，我们已经使用训练数据集成功地训练了我们的模型。在下一步中，我们将使用测试数据集测试模型的性能。

### 步骤 3-测试集结果的预测:

我们模型的最后一步是检查模型的性能。我们将通过预测测试集结果来做到这一点。为了预测，我们将创建一个 **y_pred** 向量。下面是它的代码:

```

#Predicting the Test set result;
y_pred= regressor.predict(x_test)

```

通过执行上述代码行，将在变量资源管理器选项下生成一个新向量。我们可以通过比较预测值和测试集值来测试我们的模型。

**输出:**

![Multiple Linear Regression](../Images/fc5dc464203fd6a412d2d00e35b39432.png)

在上面的输出中，我们已经预测了结果集和测试集。我们可以通过逐个比较这两个值索引来检查模型性能。例如，第一个指数的预测值为 **103015$** 利润，测试/真实值为 **103282$** 利润。差别只是 **267$** ，这个预测不错，所以，最后我们的模型在这里完成了。

*   我们还可以检查训练数据集和测试数据集的分数。下面是它的代码:

```

print('Train Score: ', regressor.score(x_train, y_train))
print('Test Score: ', regressor.score(x_test, y_test))

```

**输出:**得分为:

```
Train Score:  0.9501847627493607
Test Score:  0.9347068473282446

```

**上述评分表明，我们的模型对训练数据集的准确率为 95%，对测试数据集的准确率为 93%。**

#### 注意:在下一个主题中，我们将看到如何使用向后淘汰过程来提高模型的性能。

### 多元线性回归的应用:

多元线性回归主要有两种应用:

*   自变量对预测的有效性:
*   预测变化的影响:

* * *