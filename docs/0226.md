# 与 Hadoop 的集成

> 原文:[https://www.javatpoint.com/r-hadoop-integration](https://www.javatpoint.com/r-hadoop-integration)

## 什么是 Hadoop？

**Hadoop** 是由 **ASF - Apache 软件基金会**创立的开源框架。它用于存储、处理和分析海量数据。Hadoop 是用 Java 写的，不是 OLAP(在线分析处理)。用于批量/离线处理。它被脸书、谷歌、推特、雅虎、领英和许多其他公司使用。此外，只需在集群中添加节点，就可以扩大规模。

## 为什么要将 R 与 Hadoop 集成？

r 是一种开源编程语言。它最适合统计和图形分析。此外，如果我们需要强大的数据分析和可视化功能，我们必须将 R 与 Hadoop 相结合。

R 和 Hadoop 集成背后的目的:

1.  使用 Hadoop 执行 R 代码。
2.  用 R 访问 Hadoop 中存储的数据。

## 面向对象的集成方法

Hadoop 和 R 在大数据可视化和分析方面非常互补。Hadoop 和 R 一起使用的方式有四种，分别如下:

![R integration with Hadoop](../Images/294e4d8c18df9325da54dc29adb4b567.png)

### R Hadoop

R Hadoop 方法是包的集合。它包含三个包，即 rmr、rhbase 和 rhdfs。

**rmr 包**

对于 Hadoop 框架，rmr 包通过在 r

**rhbase 包**

这个包提供了与 HBASE 集成的数据库管理功能。

**rhd fs 包**

该软件包通过与 HDFS 集成来提供文件管理功能。

### Hadoop 流

Hadoop Streaming 是一个实用程序，允许用户创建和运行任何可执行文件作为映射器和/或缩减器的作业。使用流系统，我们可以用足够的 Java 知识开发工作的 Hadoop 作业，以编写两个协同工作的 shell 脚本。

R 和 Hadoop 的结合似乎是处理大型数据集和统计数据的人的必备工具包。然而，一些 Hadoop 爱好者在处理非常大的大数据摘录时提出了一个警告。他们声称 R 的好处不是它的语法，而是可视化和数据的整个原语库。这些库基本上是非分布式的，使得数据检索成为一件耗时的事情。这是 R 的一个固有缺陷，如果你选择忽略它，R 和 Hadoop 都可以协同工作。

### 瑞佩

RHIPE 代表 **R 和 Hadoop 集成编程环境**。对开发的 RHIPE 进行拆分和重组，以便对大量数据进行高效分析。

RHIPE 涉及使用 R 和 Hadoop 集成编程环境。我们可以使用 Python、Perl 或 Java 来读取 RHIPE 中的数据集。RHIPE 中有各种功能，可以让 HDFS 与 HDFS 互动。因此，通过这种方式，我们可以读取、保存使用 RHIPE MapReduce 创建的完整数据。

### 乐团

ORCH 被称为甲骨文公司。这种方法特别适用于 Oracle 设备中的大数据。它也用于非 Oracle 框架，如 Hadoop。

这种方法有助于借助 R 访问 Hadoop 集群，也有助于编写映射和归约函数。它允许我们操作驻留在 Hadoop 分布式文件系统中的数据。

* * *