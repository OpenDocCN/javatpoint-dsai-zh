# 硬后端

> 原文：<https://www.javatpoint.com/keras-backends>

Keras 是一个模型级的库，提供了对开发深度学习模型有用的高级构造块。而不是支持诸如张量积、卷积等低级运算。本身，它依赖于后端引擎，该引擎是非常专业和优化的张量操作库。它不会只选择一个张量库来实现与该特定库相关联的 Keras。它通过将许多不同的后端引擎无缝插入 Keras，以模块化的方式处理这种情况。

以下是三个可用的后端实现，如下所示；

*   **TensorFlow:** 这个谷歌开发的符号张量操作框架是开源的。
*   **antao:**这也是一个开源的张量符号操作框架，由 LISA 实验室在蒙特利尔大学开发。
*   **CNTK:** 由微软开发，也是开源的深度学习工具包。

## 从一个后端切换到另一个后端

您可能会在以下位置找到 Keras 配置文件:

**$HOME/.hard/hard.json**

如果你在那里找到它时遇到了问题，那么你可以创建一个！

#### 注意:特别是对于 Windows 用户，您必须用%USERPROFILE%替换$HOME。

以下是默认配置；

```

{
    "image_data_format": "channels_last",
    "epsilon": 1e-07,
    "floatx": "float32",
    "backend": "tensorflow"
}

```

在这里，您只需将**后端**字段更改为**【茶诺】****【张量流】**或**【cntk】**，然后 [Keras](https://www.javatpoint.com/keras) 将在您运行任何 Keras 代码时使用修改后的配置。

一旦定义了**KERAS _ 后端**环境变量，它将覆盖配置文件中定义的任何内容:

```

KERAS_BACKEND=tensorflow python -c "from keras import backend"
Using TensorFlow backend.

```

您可能可以在 Keras 中加载更多后端，然后是**“tensorflow”**、**“antao”**或**“cntk”**，因为它可以轻松利用外部后端。这可以通过更改 **keras.json** 和**“后端”**设置来完成。假设您有一个名为 **my_module** 的 [Python](https://www.javatpoint.com/python-tutorial) 模块作为外部后端；那么，在这种情况下， **keras.json** 文件可能会发生一些变化，具体如下；

```

{
    "image_data_format": "channels_last",
    "epsilon": 1e-07,
    "floatx": "float32",
    "backend": "my_package.my_module"
}

```

为了使用外部后端，它必须经过验证，并包含像**占位符**、**变量**和**函数**这样的函数。

如果外部后端无效，它可能会生成一个错误，其中可能包含所有丢失的条目。

## keras.json 详细信息

以下是包含在 **keras.json** 文件中的设置:

```

{
    "image_data_format": "channels_last",
    "epsilon": 1e-07,
    "floatx": "float32",
    "backend": "tensorflow"
}

```

只需编辑 **$HOME/，即可修改设置。keras/keras.json** 。

*   **image_data_format:** 可以定义为字符串，可以是“channels_last”也可以是“channels_first”，指定约定数据格式后接 Keras。(由**后端返回。**
*   对于任何二维数据，如图像，**“通道 _ 最后”**将采用**(行、列、通道)**，而**“通道 _ 第一”**将采用**(通道、行、列)**。
*   对于任何三维数据，**“channels _ last”**将与 **(conv_dim1，conv_dim2，conv_dim3，通道)**相关，而**“channels _ first”**将与**(通道，conv_dim1，conv_dim2，conv_dim3)** 相关。
*   **ε:**它指的是一个浮点数，这是一个模糊的数字常数，用于避免在某些操作中被零除。
*   **float tx:**表示一串**【float 16】****【float 32】**或**【float 64】**。默认情况下，它是浮点精度。
*   **后端:**它指的是一串“tensorflow”、“茶诺”或“cntk”。

## 使用抽象的 Keras 后端编写新代码

借助抽象的 Keras 后端 API，您可以使您编写的 Keras 模块更兼容 antio(**th**)和 TensorFlow ( **tf** )。以下是对它的介绍；

后端模块可以通过以下方式导入:

```

from keras import backend as K

```

输入占位符将由下面给出的代码实例化，该代码等于 **tf.placeholder()** 或 **th.tensor.matrix()，th . tensor 3()**等。

```

inputs = K.placeholder(shape=(2, 4, 5))
# also works:
inputs = K.placeholder(shape=(None, 4, 5))
# also works:
inputs = K.placeholder(ndim=3)

```

一个变量将通过合并以下代码来实例化，该代码返回等于 **tf。变量()**或 **th.shared()** 。

```

import numpy as np
val = np.random.random((3, 4, 5))
var = K.variable(value=val)

# all-zeros variable:
var = K.zeros(shape=(3, 4, 5))
# all-ones:
var = K.ones(shape=(3, 4, 5))

```

您可能需要的大部分张量运算将以类似于您在[张量流](https://www.javatpoint.com/tensorflow)或 Anano 中的方式执行，如下所示:

```

 # Initializing Tensors with Random Numbers
b = K.random_uniform_variable(shape=(3, 4), low=0, high=1) # Uniform distribution
c = K.random_normal_variable(shape=(3, 4), mean=0, scale=1) # Gaussian distribution
d = K.random_normal_variable(shape=(3, 4), mean=0, scale=1)

# Tensor Arithmetic
a = b + c * K.abs(d)
c = K.dot(a, K.transpose(b))
a = K.sum(b, axis=1)
a = K.softmax(b)
a = K.concatenate([b, c], axis=-1)
# etc...

```

## 后端功能

**后端**

```

keras.backend.backend()

```

后端功能用于恢复当前的后端名称。

**返回**

它返回一个字符串，该字符串与正在使用的支持的当前名称相关。

**例**

```

>>> keras.backend.backend()
'tensorflow'

```

**象征性的**

```

keras.backend.symbolic(func)

```

它可以被定义为装饰器，在 TensorFlow 2.0 中用于进入 Keras 图。

**论据**

*   **功能:**是指用来装饰的功能。

**返回**

它返回一个修饰函数。

**急切**

```

keras.backend.eager(func)

```

它可以被定义为装饰器，在 TensorFlow 2.0 中用于退出 Keras 图。

**论据**

*   **功能:**是指用来装饰的功能。

**返回**

它返回一个修饰函数。

**get_uid**

```

keras.backend.get_uid(prefix='')

```

它提供了一个唯一的 UID，该 UID 给出了一个字符串前缀。

**论据**

*   **前缀:**指字符串。

**返回**

这个后端函数返回一个整数。

**例**

```

>>> keras.backend.get_uid('dense')
1
>>> keras.backend.get_uid('dense')
2

```

该功能用于设置手动变量初始化标志。该标志被指示为一个布尔值，该值控制要初始化的变量，或者用户必须处理初始化，因为默认情况下它们是自实例化的。

**论据**

*   **值:**指 Python 的布尔值。

**ε**

```

keras.backend.epsilon()

```

它用于返回数值表达式中使用的模糊因子值。

**返回**

它返回一个浮点数。

**例**

```

>>> keras.backend.epsilon()
1e-07

```

**复位 _ 指导**

```

keras.backend.reset_uids()

```

它用于重置图形标识符。

**ε**

```

tf.keras.backend.epsilon()

```

它输出一个模糊因子值，在数值表达式中使用。

**返回**

它返回一个浮点值。

**例**

```

>>> tf.keras.backend.epsilon()
1e-07

```

**set _ε**

```

keras.backend.set_epsilon(e)

```

它用于设置数值表达式中使用的模糊因子值。

**论据**

**e:** 可以定义为代表ε新值的浮点值。

**例**

```

>>> from keras import backend as K
>>> K.epsilon()
1e-07
>>> K.set_epsilon(1e-05)
>>> K.epsilon()
1e-05

```

**浮子**

```

keras.backend.floatx()

```

它用于输出浮点类型的字符串，如“float16”、“float32”、“float64”。

**返回**

它返回当前默认浮点类型的字符串。

**例**

```

>>> keras.backend.floatx()
'float32'

```

**set _ float tx**

```

keras.backend.set_floatx(floatx)

```

它用于设置默认的浮点类型值。

**论据**

*   **float tx:**是指一串 float 类型，如‘float 16’、‘float 32’或‘float 64’。

**例**

```

>>> from keras import backend as K
>>> K.floatx()
'float32'
>>> K.set_floatx('float16')
>>> K.floatx()
'float16'

```

**提升**

*   **值错误:**只要有无效值，就会产生值错误。

**cast _ to _ floatix**

```

keras.backend.cast_to_floatx(x)

```

它用于将 Numpy 数组转换为默认的 Keras 浮点类型。

**论据**

*   **x:** 指 Numpy 数组。

**返回**

它返回正被转换为新类型的同一个 Numpy 数组。

**例**

```

>>> from keras import backend as K
>>> K.floatx()
'float32'
>>> arr = numpy.array([1.0, 2.0], dtype='float64')
>>> arr.dtype
dtype('float64')
>>> new_arr = K.cast_to_floatx(arr)
>>> new_arr
array([ 1.,  2.], dtype=float32)
>>> new_arr.dtype
dtype('float32')

```

**图像 _ 数据 _ 格式**

```

keras.backend.image_data_format()

```

它用于返回默认的图像数据格式约定。

**返回**

它返回一个“channels _ first”或“channels _ last”的字符串

**例**

```

>>> keras.backend.image_data_format()
'channels_first'

```

**set_image_data_format**

```

keras.backend.set_image_data_format(data_format)

```

该函数用于设置数据格式约定的值。

**论据**

*   **data_format:** 可以定义为“channels_first”或“channels_last”的字符串。

**例**

```

>>> from keras import backend as K
>>> K.image_data_format()
'channels_first'
>>> K.set_image_data_format('channels_last')
>>> K.image_data_format()
'channels_last'

```

**提升**

*   **ValueError:** 每当有无效的 data_format 值时，就会产生 ValueError。

**学习 _ 阶段**

```

keras.backend.learning_phase()

```

它输出一个学习阶段的标志，这是指一个布尔张量(0 =测试，1 =训练)作为输入传递给任何一个在训练和测试时使用不同行为的 Keras 函数。

**返回**

它返回学习阶段的标量整数张量或 Python 整数。

**设置 _ 学习 _ 阶段**

```

keras.backend.set_learning_phase(value)

```

它用于为学习阶段设置一个固定值。

**论据**

*   **值:**可以定义为表示学习阶段值为 0 或 1 的整数。

**提升**

*   **值错误:**如果值既不为 0 也不为 1，则引发。

**清除 _ 会话**

```

keras.backend.clear_session()

```

它用于重置喀拉斯产生的每一个状态。用于实现功能模型构建[应用编程接口](https://www.javatpoint.com/api-full-form)以及统一自动生成的图层名称的全局状态由 Keras 处理。

当在一个循环中构建多个模型时，在某个时间段内，全局状态将消耗越来越多的内存，您可能希望清除它。

它用于破坏喀拉斯的当前图形并创建一个新图形。它非常有用，因为它避免了旧模型/图层的混乱。

**示例 1:在循环中创建模型时调用 clear_session()。**

```

for _ in range(100):
  # Without `clear_session()`, each iteration of this loop will
  # slightly increase the size of the global state managed by Keras
  model = tf.keras.Sequential([tf.keras.layers.Dense(10) for _ in range(10)])

for _ in range(100):
  # With `clear_session()` called at the beginning,
  # Keras starts with a blank state at each iteration
  # and memory consumption is constant over time.
  tf.keras.backend.clear_session()
  model = tf.keras.Sequential([tf.keras.layers.Dense(10) for _ in range(10)])

```

**示例 2:重置图层名称生成计数器。**

```

>>> import tensorflow as tf
>>> layers = [tf.keras.layers.Dense(10) for _ in range(10)]
>>> new_layer = tf.keras.layers.Dense(10)
>>> print(new_layer.name)
dense_10
>>> tf.keras.backend.set_learning_phase(1)
>>> print(tf.keras.backend.learning_phase())
1
>>> tf.keras.backend.clear_session()
>>> new_layer = tf.keras.layers.Dense(10)
>>> print(new_layer.name)
dense

```

**是 _ 稀疏**

```

keras.backend.is_sparse(tensor)

```

它用于返回张量是否为稀疏张量。

**论据**

*   **张量:**指张量的一个实例。

**返回**

它返回一个布尔值。

**例**

```

>>> from keras import backend as K
>>> a = K.placeholder((2, 2), sparse=False)
>>> print(K.is_sparse(a))
False
>>> b = K.placeholder((2, 2), sparse=True)
>>> print(K.is_sparse(b))
True

```

**至 _ 密**

```

keras.backend.to_dense(tensor)

```

它用于将稀疏张量转换为稠密张量并返回。

**论据**

*   **张量:**它指的是张量的一个实例(可能是稀疏的)。

**返回**

它返回一个稠密张量。

**例**

```

>>> from keras import backend as K
>>> b = K.placeholder((2, 2), sparse=True)
>>> print(K.is_sparse(b))
True
>>> c = K.to_dense(b)
>>> print(K.is_sparse(c))
False

```

**变量**

```

keras.backend.variable(value, dtype=None, name=None, constraint=None)

```

它有助于实例化并返回一个变量。

**论据**

*   **值:**可以定义为代表张量初始值的 numpy 数组。
*   **数据类型:**指张量的类型。
*   **名称:**对于张量，它表示字符串名称。
*   **约束:**它是指在更新优化器后对变量实现的可选投影函数。

**返回**

它返回一个包含 Keras 元数据的变量实例。

**例**

```

>>> from keras import backend as K
>>> val = np.array([[1, 2], [3, 4]])
>>> kvar = K.variable(value=val, dtype='float64', name='example_var')
>>> K.dtype(kvar)
'float64'
>>> print(kvar)
example_var
>>> K.eval(kvar)
array([[ 1.,  2.],
       [ 3.,  4.]])

```

**是 _ 变量**

```

keras.backend.is_variable(x)

```

**不变**

```

keras.backend.constant(value, dtype=None, shape=None, name=None)

```

它导致了一个独特张量的产生。

**论据**

*   **值:**指常数值或列表。
*   **数据类型:**指张量的类型。
*   **名称:**对于张量，它表示字符串名称。
*   **形状:**可以定义为结果张量的维度，这是可选的。

**返回**

它还返回一个唯一张量。

**is_keras_tensor**

```

keras.backend.is_keras_tensor(x)

```

输出 **x** 是否为 Keras 张量。“喀拉斯张量”是由喀拉斯层(**层**类)或由**输入**返回的张量。

**论据**

*   **x:** 指的是一个候选张量。

**返回**

它返回一个布尔值，表示参数是否是 Keras 张量。

**提升**

如果 x 不是符号张量，它会引发 ValueError。

**例**

```

>>> from keras import backend as K
>>> from keras.layers import Input, Dense
>>> np_var = numpy.array([1, 2])
>>> K.is_keras_tensor(np_var) # A numpy array is not a symbolic tensor.
ValueError
>>> k_var = tf.placeholder('float32', shape=(1,1))
>>> # A variable indirectly created outside of keras is not a Keras tensor.
>>> K.is_keras_tensor(k_var)
False
>>> keras_var = K.variable(np_var)
>>> # A variable created with the keras backend is not a Keras tensor.
>>> K.is_keras_tensor(keras_var)
False
>>> keras_placeholder = K.placeholder(shape=(2, 4, 5))
>>> # A placeholder is not a Keras tensor.
>>> K.is_keras_tensor(keras_placeholder)
False
>>> keras_input = Input([10])
>>> K.is_keras_tensor(keras_input) # An Input is a Keras tensor.
True
>>> keras_layer_output = Dense(10)(keras_input)
>>> # Any Keras layer output is a Keras tensor.
>>> K.is_keras_tensor(keras_layer_output)
True

```

**是 _ 张量**

```

keras.backend.is_tensor(x)

```

**占位符**

```

keras.backend.placeholder(shape=None, ndim=None, dtype=None, sparse=False, name=None)

```

它有助于实例化占位符张量并返回它。

**论据**

*   **形状:**它可以被定义为一个元组整数，它可以包含**无**条目来帮助表示占位符的形状。
*   **ndim:** 是指张量轴的个数，指定{ **形**、 **ndim** 中的至少一个。如果两者都指定，则使用**形状**。
*   **数据类型:**定义占位符的类型。
*   **稀疏:**可以定义为一个布尔值，表示占位符是否具有稀疏类型。
*   **名称:**这是一个可选参数，用于定义占位符名称的字符串。

**返回**

它通过包含一个 Keras 元数据返回一个 Tensor 的实例。

**例**

```

>>> from keras import backend as K
>>> input_ph = K.placeholder(shape=(2, 4, 5))
>>> input_ph._keras_shape
(2, 4, 5)
>>> input_ph

```

**是 _ 占位符**

```

keras.backend.is_placeholder(x)

```

如果 **x** 是否为占位符，则返回。

**论据**

*   **x:** 可以定义为候选占位符。

**返回**

它返回一个布尔值。

**形状**

```

keras.backend.shape(x)

```

它输出张量或变量的符号形状。

**论据**

*   **x:** 指张量或变量。

**返回**

它返回一个符号形状的张量。

**示例**

```

# TensorFlow example
>>> from keras import backend as K
>>> tf_session = K.get_session()
>>> val = np.array([[1, 2], [3, 4]])
>>> kvar = K.variable(value=val)
>>> inputs = keras.backend.placeholder(shape=(2, 4, 5))
>>> K.shape(kvar)
 >>> K.shape(inputs)
 <tf.tensor shape="(3,)" dtype="int32"># To get integer shape (Instead, you can use K.int_shape(x))
>>> K.shape(kvar).eval(session=tf_session)
array([2, 2], dtype=int32)
>>> K.shape(inputs).eval(session=tf_session)
array([2, 4, 5], dtype=int32)</tf.tensor> 
```

**int_shape**

```

keras.backend.int_shape(x)

```

它可以被定义为输出张量或变量形状的 int 或 None 条目的元组。

**论据**

*   **x:** 指张量或变量。

**返回**

它要么返回整数元组，要么返回无条目。

**例**

```

>>> from keras import backend as K
>>> inputs = K.placeholder(shape=(2, 4, 5))
>>> K.int_shape(inputs)
(2, 4, 5)
>>> val = np.array([[1, 2], [3, 4]])
>>> kvar = K.variable(value=val)
>>> K.int_shape(kvar)
(2, 2)

```

**Numpy 实现**

```

def int_shape(x):
    return x.shape

```

ndim

```

keras.backend.ndim(x)

```

它指的是作为张量中的轴数返回的整数。

**论据**

*   **x:** 既可以定义为张量，也可以定义为变量。

**返回**

它将轴的数量输出为整数值。

**例**

```

>>> from keras import backend as K
>>> inputs = K.placeholder(shape=(2, 4, 5))
>>> val = np.array([[1, 2], [3, 4]])
>>> kvar = K.variable(value=val)
>>> K.ndim(inputs)
3
>>> K.ndim(kvar)
2

```

**Numpy 实现**

```

def ndim(x):
    return x.ndim

```

**尺寸**

```

keras.backend.size(x, name=None)

```

它输出张量大小。

**论据**

*   **x:** 既可以定义为张量，也可以定义为变量。
*   **名称:**是可选的关键字参数，表示操作的名称。

**返回**

它返回张量的大小。

**例**

```

>>> from keras import backend as K
>>> val = np.array([[1, 2], [3, 4]])
>>> kvar = K.variable(value=val)
>>> K.size(inputs)

```

dtype

```

keras.backend.dtype(x)

```

它可以定义为字符串，作为 Keras 张量或变量的数据类型返回。

**论据**

*   **x:** 既可以定义为张量，也可以定义为变量。

**返回**

对于 x，它返回它的数据类型。

**例**

```

>>> from keras import backend as K
>>> K.dtype(K.placeholder(shape=(2,4,5)))
'float32'
>>> K.dtype(K.placeholder(shape=(2,4,5), dtype='float32'))
'float32'
>>> K.dtype(K.placeholder(shape=(2,4,5), dtype='float64'))
'float64'
# Keras variable
>>> kvar = K.variable(np.array([[1, 2], [3, 4]]))
>>> K.dtype(kvar)
'float32_ref'
>>> kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')
>>> K.dtype(kvar)
'float32_ref'

```

**Numpy 实现**

```

def dtype(x):
    return x.dtype.name

```

eval

```

keras.backend.eval(x)

```

它有助于评估张量值。

**论据**

*   **x:** 可以定义为张量。

**返回**

它输出一个 Numpy 数组。

**例**

```

>>> from keras import backend as K
>>> kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')
>>> K.eval(kvar)
array([[ 1.,  2.],
       [ 3.,  4.]], dtype=float32)

```

**Numpy 实现**

```

def eval(x):
    return x

```

**零**

```

keras.backend.zeros(shape, dtype=None, name=None)

```

它有助于实例化那些全零变量，然后返回它。

**论据**

*   **形状:**可以定义为一个整数元组，表示返回的 Keras 变量的形状。
*   **dtype:** 它指的是与返回的 Keras 变量的数据类型相对应的字符串。
*   **名称:**是指代表返回的 Keras 变量名称的字符串。

**返回**

它返回一个包含 Keras 元数据的变量，该变量用 0.0 填充。需要注意的是，如果它是符号 n 形状，那么一个变量不能被返回，而是一个动态形状的张量将被返回。

**例**

```

>>> from keras import backend as K
>>> kvar = K.zeros((3,4))
>>> K.eval(kvar)
array([[ 0.,  0.,  0.,  0.],
       [ 0.,  0.,  0.,  0.],
       [ 0.,  0.,  0.,  0.]], dtype=float32)

```

**Numpy 实现**

```

def zeros(shape, dtype=floatx(), name=None):
    return np.zeros(shape, dtype=dtype)

```

**个**

```

keras.backend.ones(shape, dtype=None, name=None)

```

它有助于实例化全 1 变量，然后返回它。

**论据**

*   **形状:**可以定义为一个整数元组，表示返回的 Keras 变量的形状。
*   **dtype:** 它指的是与返回的 Keras 变量的数据类型相对应的字符串。
*   **名称:**是指代表返回的 Keras 变量名称的字符串。

**返回**

它返回一个 Keras 变量，用 0.0 填充。需要注意的是，如果它是符号 n 形状，那么一个变量不能被返回，而是一个动态形状的张量将被返回。

**例**

```

>>> from keras import backend as K
>>> kvar = K.ones((3,4))
>>> K.eval(kvar)
array([[ 1.,  1.,  1.,  1.],
       [ 1.,  1.,  1.,  1.],
       [ 1.,  1.,  1.,  1.]], dtype=float32)

```

**Numpy 实现**

```

def ones(shape, dtype=floatx(), name=None):
    return np.ones(shape, dtype=dtype)

```

**眼**

```

keras.backend.eye(size, dtype=None, name=None)

```

它有助于身份矩阵的实例化，然后返回它。

**论据**

*   **大小:**既可以定义为定义行数和列数的元组，也可以定义为表示行数的整数。
*   **dtype:** 它指的是与返回的 Keras 变量的数据类型相对应的字符串。
*   **名称:**是指代表返回的 Keras 变量名称的字符串。

**返回**

它输出一个代表单位矩阵的 Keras 变量。

**例**

```

>>> from keras import backend as K
>>> K.eval(K.eye(3))
array([[ 1.,  0.,  0.],
       [ 0.,  1.,  0.],
       [ 0.,  0.,  1.]], dtype=float32)
>>> K.eval(K.eye((2, 3)))
array([[1., 0., 0.],
       [0., 1., 0.]], dtype=float32)

```

**Numpy 实现**

```

def eye(size, dtype=None, name=None):
    if isinstance(size, (list, tuple)):
        n, m = size
    else:
        n, m = size, size
    return np.eye(n, m, dtype=dtype)

```

**类零**

```

keras.backend.zeros_like(x, dtype=None, name=None)

```

它有助于将全零的相似形状变量实例化为另一个张量。

**论据**

*   **x:** 既可以定义为 Keras 变量，也可以定义为 Keras 张量。
*   **dtype:** 它指的是与返回的 Keras 变量的数据类型相对应的字符串。这里的无与 x 数据类型的使用有关。
*   **名称:**是指代表返回的 Keras 变量名称的字符串。

**返回**

它返回一个用全零填充的 Keras 变量，构成 x 的形状。

**例**

```

>>> from keras import backend as K
>>> kvar = K.variable(np.random.random((2,3)))
>>> kvar_zeros = K.zeros_like(kvar)
>>> K.eval(kvar_zeros)
array([[ 0.,  0.,  0.],
       [ 0.,  0.,  0.]], dtype=float32)

```

**Numpy 实现**

```

def zeros_like(x, dtype=floatx(), name=None):
    return np.zeros_like(x, dtype=dtype)

```

**类似**的

```

keras.backend.ones_like(x, dtype=None, name=None)

```

它有助于实例化相似的形状变量，这些变量作为另一个张量是全 1 的。

**论据**

*   **x:** 既可以定义为 Keras 变量，也可以定义为 Keras 张量。
*   **dtype:** 它指的是与返回的 Keras 变量的数据类型相对应的字符串。这里的无与 x 数据类型的使用有关。
*   **名称:**是指代表返回的 Keras 变量名称的字符串。

**返回**

它返回一个用全零填充的 Keras 变量，构成 x 的形状。

**例**

```

>>> from keras import backend as K
>>> kvar = K.variable(np.random.random((2,3)))
>>> kvar_ones = K.ones_like(kvar)
>>> K.eval(kvar_ones)
array([[ 1.,  1.,  1.],
       [ 1.,  1.,  1.]], dtype=float32)

```

**Numpy 实现**

```

def ones_like(x, dtype=floatx(), name=None):
    return np.ones_like(x, dtype=dtype)

```

**身份**

```

keras.backend.identity(x, name=None)

```

它输出一个与输入张量内容相似的张量。

**论据**

*   **x:** 指输入张量。
*   **名称:**是指代表变量名称的字符串，必须创建。

**返回**

它返回一个具有相同形状、类型和内容的张量。

**随机 _ 均匀 _ 变量**

```

keras.backend.random_uniform_variable(shape, low, high, dtype=None, name=None, seed=None)

```

它强调一个变量的实例化，这个变量的值来自于一个均匀的分布。

**论据**

*   **形状:**可以定义为一个整数元组，表示返回的 Keras 变量的形状。
*   **低:**表示代表输出区间下限的浮点值。
*   **高:**表示一个浮点值，代表输出区间的上边界。
*   **dtype:** 它指的是与返回的 Keras 变量的数据类型相对应的字符串。
*   **名称:**可以定义为与返回的 Keras 变量名称相关的字符串。
*   **种子:**可以定义为代表随机种子的整数。

**返回**

它输出一个已经用绘制的样本填充的 Keras 变量。

**例**

```

# TensorFlow example
>>> kvar = K.random_uniform_variable((2,3), 0, 1)
>>> kvar
 >>> K.eval(kvar)
array([[ 0.10940075,  0.10047495,  0.476143  ],
       [ 0.66137183,  0.00869417,  0.89220798]], dtype=float32) 
```

**Numpy 实现**

```

def random_uniform_variable(shape, low, high, dtype=None, name=None, seed=None):
    return (high - low) * np.random.random(shape).astype(dtype) + low

```

**随机 _ 正常 _ 变量**

```

keras.backend.random_normal_variable(shape, mean, scale, dtype=None, name=None, seed=None)

```

它有助于一个变量的实例化，这个变量的值来自正态分布。

**论据**

*   **形状:**可以定义为一个整数元组，表示返回的 Keras 变量的形状
*   **均值:**指代表正态分布均值的浮点数。
*   **标度:**指代表正态分布标准差的浮点数。
*   **dtype:** 可以定义为代表返回的 Keras 变量的 dtype 的字符串。
*   **名称:**它指的是一个 String，表示返回的 Keras 变量的名称。
*   **种子:**指代表随机种子的整数。

**返回**

它输出一个已经用绘制的样本填充的 Keras 变量。

**例**

```

# TensorFlow example
>>> kvar = K.random_normal_variable((2,3), 0, 1)
>>> kvar
 >>> K.eval(kvar)
array([[ 1.19591331,  0.68685907, -0.63814116],
       [ 0.92629528,  0.28055015,  1.70484698]], dtype=float32) 
```

**Numpy 实现**

```

def random_normal_variable(shape, mean, scale, dtype=None, name=None, seed=None):
    return scale * np.random.randn(*shape).astype(dtype) + mean

```

**计数 _ 参数**

```

keras.backend.count_params(x)

```

它输出位于一个 Keras 变量或张量内的恒定数量的分量。

**论据**

*   **x:** 指一个 Keras 变量或张量。

**返回**

它产生一个整数，描述 x 中存在的元素总数，即数组静态维数的乘积。

**例**

```

>>> kvar = K.zeros((2,3))
>>> K.count_params(kvar)
6
>>> K.eval(kvar)
array([[ 0.,  0.,  0.],
       [ 0.,  0.,  0.]], dtype=float32)

```

**Numpy 实现**

```

def count_params(x):
    return x.size

```

**铸造**

```

keras.backend.cast(x, dtype)

```

它有助于将张量转换为不同的数据类型，然后将其返回。在这种情况下，如果你投射一个 Keras 变量，那么它也会产生一个 Keras 张量。

**论据**

*   **x:** 可以定义为 Keras 张量或变量。
*   **数据类型:**是指“ **float16** ”、“ **float32** ”或“ **float64** 中的一个字符串。

**返回**

它输出一个带有数据类型**数据类型**的 Keras 张量。

**例**

```

>>> from keras import backend as K
>>> input = K.placeholder((2, 3), dtype='float32')
>>> input
 # It doesn't work in-place as below.
>>> K.cast(input, dtype='float16')
 <tf.tensor shape="(2," dtype="float16">>>> input
 <tf.tensor shape="(2," dtype="float32"># you need to assign it.
>>> input = K.cast(input, dtype='float16')
>>> input</tf.tensor></tf.tensor> 
```

**更新**

```

keras.backend.update(x, new_x)

```

它有助于将 **x** 的值更新为 **new_x** 。

**论据**

*   **x:** 指的是一个**变量**。
*   **new_x:** 可以定义为与 **x** 形状相似的张量。

**返回**

它导致更新的 **x** 变量

**更新 _ 添加**

```

keras.backend.update_add(x, increment)

```

它增加了一个**增量**，这有助于更新 **x** 的值。

**论据**

*   **x:** 指的是一个**变量**。
*   **增量:**可以定义为形状与 **x** 相似的张量。

**返回**

它返回更新的 **x** 变量。

**更新 _sub**

```

keras.backend.update_sub(x, decrement)

```

减去减量，更新 **x** 的值。

**论据**

*   **x:** 可以定义为变量。
*   **减量:**是指与 **x** 形状相似的张量。

**返回**

它返回更新的 **x** 变量。

**移动平均线 _ 更新**

```

keras.backend.moving_average_update(x, value, momentum)

```

对于一个变量，它计算其移动平均值。

**论据**

*   **x:** 指一个变量。
*   **值:**可以定义为与 **x** 形状相同的张量。
*   **动量:**指一个静态平均动量。

**返回**

它输出一个操作，用于更新变量。

**点**

```

keras.backend.dot(x, y)

```

它通过乘以 2 个张量或变量返回一个张量。

当一个 nD 张量乘以另一个 nD 张量时，一个 Anano 行为被再现。(例如(2，3) * (4，3，5) -> (2，4，5))

**论据**

*   **x:** 指张量或变量。
*   **y:** 指张量或变量。

**返回**

它返回一个张量，这个张量是在 x 和 y 之间进行点积后产生的。

**示例**

```

# dot product between tensors
>>> x = K.placeholder(shape=(2, 3))
>>> y = K.placeholder(shape=(3, 4))
>>> xy = K.dot(x, y)
>>> xy
 # dot product between tensors
>>> x = K.placeholder(shape=(32, 28, 3))
>>> y = K.placeholder(shape=(3, 4))
>>> xy = K.dot(x, y)
>>> xy
 <tf.tensor shape="(32," dtype="float32"># Theano-like behavior example
>>> x = K.random_uniform_variable(shape=(2, 3), low=0, high=1)
>>> y = K.ones((4, 3, 5))
>>> xy = K.dot(x, y)
>>> K.int_shape(xy)
(2, 4, 5)</tf.tensor> 
```

**Numpy 实现**

```

def dot(x, y):
    return np.dot(x, y)

```

**批次 _ 点**

```

keras.backend.batch_dot(x, y, axes=None)

```

**batch_dot** 用于计算 **x** 和 **y** 之间的分批点积，其中 x 和 y 是批次内部的数据(即，以**的形状(batch_size，)**)。它要么输出包含比输入更少维度的张量或变量。如果我们将维度的数量减少到 1，那么我们可以使用 **expand_dims** ，这确保 ndim 至少为 2。

**论据**

*   **x:** 指 ndim 大于或等于 2 的 Keras 张量或变量。
*   **y:** 指 ndim 大于或等于 2 的 Keras 张量或变量。
*   **坐标轴:**可以定义为一个 int 或 tuple(int，int)，强调要降维的目标的维度。

**返回**

它返回一个张量，该张量的形状与 **x** 的形状和 **y** 的形状的连接相同()。这里, **x** 的形状与累加的尺寸越小相关，而 **y** 表示批量尺寸和累加的尺寸越小。但是，如果最终排名为 1，则重新塑造为 **(batch_size，1)** 。

**示例**

假设 x = [[1，2]，[3，4]]和 y = [[5，6]，[7，8]] batch_dot(x，y，axes=1) = [[17]，[53]]是 x.dot(y.T)的主对角线，虽然我们从来不需要计算非对角线元素。

伪代码:

```

inner_products = []
for xi, yi in zip(x, y):
    inner_products.append(xi.dot(yi))
result = stack(inner_products)

```

形状推断:让 x 的形状为(100，20)，y 的形状为(100，30，20)。如果轴是(1，2)，要找到合成张量的输出形状，循环通过 x 形状和 y 形状的每个维度:

*   形状[0] : 100:追加到输出形状
*   形状[1] : 20:不要追加到输出形状，x 的维度 1 已被求和。(点轴[0] = 1)
*   形状[0] : 100:不要追加到输出形状，始终忽略 y 的第一维
*   形状[1] : 30:追加到输出形状
*   形状[2] : 20:不要追加到输出形状，y 的维度 2 已被求和。(点轴[1] = 2)输出形状= (100，30)

```

>>> x_batch = K.ones(shape=(32, 20, 1))
>>> y_batch = K.ones(shape=(32, 30, 20))
>>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=(1, 2))
>>> K.int_shape(xy_batch_dot)
(32, 1, 30)

```

**转置**

```

keras.backend.transpose(x)

```

它用于转置张量，然后返回张量。

**论据**

*   **x:** 既可以是张量，也可以是变量。

**返回**

它返回一个张量。

**示例**

```

>>> var = K.variable([[1, 2, 3], [4, 5, 6]])
>>> K.eval(var)
array([[ 1.,  2.,  3.],
       [ 4.,  5.,  6.]], dtype=float32)
>>> var_transposed = K.transpose(var)
>>> K.eval(var_transposed)
array([[ 1.,  4.],
       [ 2.,  5.],
       [ 3.,  6.]], dtype=float32)
>>> inputs = K.placeholder((2, 3))
>>> inputs
 >>> input_transposed = K.transpose(inputs)
>>> input_transposed 
```

**Numpy 实现**

```

def transpose(x):
    return np.transpose(x)

```

**聚集**

```

keras.backend.gather(reference, indices)

```

它有助于检索张量的**参考**内的索引**索引**元素。

**论据**

*   **参考:**它指的是一个张量。
*   **指数:**可以定义为代表指数张量的整数。

**返回**

它输出与**参考**相同类型的张量。

**Numpy 实现**

```

def gather(reference, indices):
    return reference[indices]

```

**最大值**

```

keras.backend.max(x, axis=None, keepdims=False)

```

它计算张量的最大值。

**论据**

*   **x:** 可以定义为张量或变量。
*   **轴:**指的是[-rank(x)，rank(x))(用于计算最大值的轴)内部的一个或多个整数列表。如果设置为**无**(默认)，则计算最大外形尺寸。
*   **keepdims:** 是决定是否保留尺寸的布尔值。如果**保留**设置为**假**，那么张量的等级将减少 1。否则，如果 keepdims 设置为 **True** ，则缩减的尺寸将保留长度 1。

**返回**

它返回一个张量，表示 x 的最大值。

**Numpy 实现**

```

def max(x, axis=None, keepdims=False):
    if isinstance(axis, list):
        axis = tuple(axis)
    return np.max(x, axis=axis, keepdims=keepdims)

```

**分钟**

```

keras.backend.min(x, axis=None, keepdims=False)

```

它计算张量内部的最小值。

**论据**

*   **x:** 可以定义为张量或变量。
*   **轴:**指的是[-rank(x)，rank(x))(用于计算最小值的轴)内的一个或多个整数列表。如果设置为**无**(默认)，则计算最小总尺寸。
*   **keepdims:** 是决定是否保留尺寸的布尔值。如果**保留**设置为**假**，那么张量的等级将减少 1。否则，如果 keepdims 设置为 **True** ，则缩减的尺寸将保留长度 1。

**返回**

它返回一个张量，表示 x 的最小值。

**Numpy 实现**

```

def min(x, axis=None, keepdims=False):
    if isinstance(axis, list):
        axis = tuple(axis)
    return np.min(x, axis=axis, keepdims=keepdims)

```

**总和**

```

keras.backend.sum(x, axis=None, keepdims=False)

```

它沿着指定的轴输出张量内值的总和。

**论据**

*   **x:** 可以定义为张量或变量。
*   **轴:**指的是[-rank(x)，rank(x))(用于计算总和的轴)内部存在的一个或多个整数列表。如果设置为**无**(默认)，则计算总尺寸。
*   **keepdims:** 是决定是否保留尺寸的布尔值。如果**保留**设置为**假**，那么张量的等级将减少 1。否则，如果 keepdims 设置为 **True** ，则缩减的尺寸将保留长度 1。

**返回**

它返回包含 **x** 之和的张量。

**Numpy 实现**

```

def sum(x, axis=None, keepdims=False):
    if isinstance(axis, list):
        axis = tuple(axis)
    return np.sum(x, axis=axis, keepdims=keepdims)

```

**戳**

```

keras.backend.prod(x, axis=None, keepdims=False)

```

结合特定的轴，它计算张量内部值的乘积。

**论据**

*   **x:** 可以定义为张量或变量。
*   **轴:**是指[-rank(x)，rank(x))(用于计算乘积的轴)内部存在的一个或多个整数列表。如果设置为**无**(默认)，则计算整体产品尺寸。
*   **keepdims:** 是决定是否保留尺寸的布尔值。如果**保留**设置为**假**，那么张量的等级将减少 1。否则，如果 keepdims 设置为 **True** ，则缩减的尺寸将保留长度 1。

**返回**

它返回包含 **x** 内元素乘积的张量。

**Numpy 实现**

```

def prod(x, axis=None, keepdims=False):
    if isinstance(axis, list):
        axis = tuple(axis)
    return np.prod(x, axis=axis, keepdims=keepdims)

```

cum sum

```

keras.backend.cumsum(x, axis=0)

```

结合特定的轴，它计算张量内值的累积和。

**论据**

*   **x:** 可以定义为张量或变量。
*   **轴:**指整数，是用来计算和的轴。

**返回**

它返回一个张量，包含沿**轴**的 **x** 的累积值总和。

**Numpy 实现**

```

def cumsum(x, axis=0):
    return np.cumsum(x, axis=axis)

```

cum prod

```

keras.backend.cumprod(x, axis=0)

```

结合特定的轴，它计算张量内值的累积乘积。

**论据**

*   **x:** 可以定义为张量或变量。
*   **轴:**指整数，是用来计算乘积的轴。

**返回**

它返回一个张量，包含沿**轴**的 **x** 的值的累积乘积。

**Numpy 实现**

```

def cumprod(x, axis=0):
    return np.cumprod(x, axis=axis)

```

**在**处

```

keras.backend.var(x, axis=None, keepdims=False)

```

结合特定的轴，它计算张量的方差。

**论据**

*   **x:** 可以定义为张量或变量。
*   **轴:**是指[-rank(x)，rank(x))(用于计算方差的轴)内部存在的一个或多个整数列表。如果设置为**无**(默认)，则计算整体方差维度。
*   **keepdims:** 是决定是否保留尺寸的布尔值。如果**保留**设置为**假**，那么张量的等级将减少 1。否则，如果 keepdims 设置为 **True** ，则缩减的尺寸将保留长度 1。

**返回**

它返回位于 **x** 的元素的张量方差。

**Numpy 实现**

```

def var(x, axis=None, keepdims=False):
    if isinstance(axis, list):
        axis = tuple(axis)
    return np.var(x, axis=axis, keepdims=keepdims)

```

**rnn**

```

tf.keras.backend.rnn(
    step_function,
    inputs,
    initial_states,
    go_backwards=False,
    mask=None,
    constants=None,
    unroll=False,
    input_length=None,
    time_major=False,
    zero_output_for_mask=False,
)

```

这对于在张量维度上重复是有用的。

**论据**

*   **阶跃函数:**被称为 RNN 阶跃函数。它包括下面给出的以下参数:
    *   **输入:**它包括具有**形状的张量(样本，...)**表示批次样品在特定时间步长的输入。它不包括时间维度。
    *   **状态:**可以定义为张量的列表。
    *   **new_states:** 它可以定义为一个张量列表，它构成了与状态相同的形状和长度，因此初始状态必须是列表中前一个时间步长的输出张量。

**返回**

它输出一个形状张量**(样本，output_dim)**

*   **输入:**它或者是指构成**形状的至少三维的时间数据张量(样本，时间，...)**或嵌套张量，使得每个都具有**的形状(样本，时间，...)**。
*   **初始状态:**它可以被定义为形状张量**(样本，状态大小)**，其包含在阶跃函数中使用的状态初始值。当 state_size 具有嵌套形状时，嵌套结构后面还会跟有初始状态。
*   **go _ backward:**可以定义为布尔值，如果设置为 True，则在时间维度之上以相反的顺序执行交互，然后返回相反的序列。
*   **掩码:**它指的是具有**(样本，时间，1)** 形状的二进制男高音，包括每个被掩码的零元素。
*   **常量:**可以定义为常量值列表，分布在每一个单独的步骤。
*   **展开:**它说明了应该展开 RNN 还是使用符号 while-loop。
*   **input_length:** 有无固定长度，可以根据时间维度定义为整数或一维张量。如果在没有指定掩码的情况下将其设置为可变长度输入，则它将用于掩码。
*   **time_major:** 可以定义为布尔型。如果设置为**真**，则输入输出的形状为**(时间步长批次，...)**，否则**(批次，时间步长，...)**如果设置为**假**。使用 **time_major = True** 是一项非常有效的任务，因为在 RNN 计算的开始和顶点都避免了转置。但是，大部分情况下，TensorFlow 数据存在于 batch-major 中，因此，默认情况下，该函数接受输入并以 batch-major 的形式发出输出。
*   **zero_output_for_mask:** 它指的是一个布尔值，如果设置为 true，那么它将屏蔽时间步长输出为零，否则将返回上一步输出。

**返回**

它返回一个形状的元组 **(last_output，outputs，new_states)** ，其中 last_output 与 rnn 最近的输出相关，该输出由形状**(样本，…)** 组成，输出指的是形状张量**(样本，时间，…)** ，使得每个条目**输出【s，t】**对应于样本 **s** 和时间 **t** 的阶跃函数输出，并且 new_states 可以是

**提升**

*   **值错误:**如果输入的维度小于 3，则会产生值错误。
*   **值错误:**如果**展开**设置为**真**，而输入的时间步长不是一个静态数字，也可以引发该错误。
*   **值错误:**如果提供了**遮罩**但未设置为**无**且未提供状态(即 **len(状态)==0** )，则也会生成该遮罩。

* * *