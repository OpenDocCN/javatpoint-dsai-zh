# 机器学习的挑战

> 原文：<https://www.javatpoint.com/challenges-of-machine-learning>

机器学习是人工智能(AI)和计算机科学的一个分支，它专注于应用算法和数据来复制人类的学习方式。这是一个提高机器学习准确性的过程。

在本教程中，我们将讨论机器学习的挑战

## 机器学习的挑战

近年来机器学习技术的进步无疑改善了我们的生活。然而，机器学习在公司的实施也带来了一些关于人工智能技术的伦理问题。其中一些是:

### 技术奇点:

虽然这个话题吸引了许多公众的关注，但科学家们对人工智能在不久的将来超越人类智能的概念并不感兴趣。这通常被称为超智能和超智慧，尼克·博斯特鲁姆(Nick Bostrum)将其定义为“在几乎每个领域都远超人类大脑顶端的任何智能，包括一般智慧、科学创造力和社交能力。”尽管超级智能和强大人工智能的概念在世界上并不现实，但当我们考虑自动驾驶汽车等自动系统的潜在用途时，这个概念提出了一些有趣的问题。很难想象一辆没有司机的车永远不会卷入车祸，但在这种情况下，谁会负责任呢？我们需要继续探索自动驾驶汽车，还是应该限制使用这种技术来生产鼓励驾驶员安全的半自动驾驶汽车？这个问题还没有定论。然而，随着新的和真正的人工智能技术的发展，这种伦理争论正在进行。

### 人工智能对工作的影响:

虽然大多数关于人工智能的公众舆论都围绕着失业，但这个问题应该有可能得到改变。随着每一项新的颠覆性技术的出现，我们可以看到某些职位需求的变化。例如，当我们考虑汽车行业时，许多像通用汽车这样的制造商正把精力集中在电动汽车上，以符合绿色政策。能源行业不会消失，但为其提供燃料的主要来源正在从基于燃料的能源经济向电力经济转变。人工智能必须被视为一种思考方式，因为人工智能有望将工作需求转移到不同的领域。随着数据每天的扩展和变化，将会有人能够控制这些系统。它仍然是必要的资源，以解决更有可能受到需求变化影响的行业中更复杂的问题，包括客户服务。人工智能最重要的元素及其对就业市场的影响将是帮助个人适应市场带来的新领域。

### 隐私:

隐私经常被与数据隐私安全、数据保护和安全性联系在一起讨论。这些担忧帮助政策制定者最近推进了他们的努力。例如，2016 年，GDPR 立法出台，保护欧洲联盟和欧洲经济区内个人的个人信息，使个人对其数据拥有更多控制权。在美国，各州正在制定政策，包括《加州消费者隐私法》(CCPA)，要求公司向其客户告知其数据处理情况。这项立法迫使公司考虑如何处理和存储个人身份信息(PII)。在此过程中，安全投资已成为消除任何潜在漏洞或黑客、监控和网络攻击机会的业务重点。

### 偏见和歧视:

不同智能机器中的歧视和偏见带来了几个关于使用人工智能的伦理问题。当训练数据可能有偏差时，我们如何保护自己免受偏差和歧视？虽然大多数公司对其自动化计划都有善意的意图，但路透社强调了将人工智能纳入招聘实践的意想不到的效果。当他们试图实现自动化并使其变得更容易时，亚马逊无意中基于技术领域职位的性别对潜在候选人产生了偏见，这导致他们终止了该项目。当这类事件曝光时，《哈佛商业评论》(位于 IBM 之外的链接)就人工智能在招聘实践中的应用提出了相关问题。例如，当评估一个特定工作的候选人时，你可以分析什么样的数据。

歧视和偏见不仅仅局限于人力资源职能。它们存在于从面部识别软件到社交媒体算法的各种应用中。

### 问责制:

没有控制人工智能实践的重要法律。没有强制执行的机制来确保使用符合道德的人工智能。公司遵守这些标准的主要动机是不可信的人工智能系统对其底线的负面影响。为了解决这个问题，研究人员和伦理学家合作开发了伦理框架，以规范人工智能模型的创建和使用。但是，就目前而言，它们只是为人工智能模型的发展提供指导。研究表明，分担责任和对潜在影响的认识不足对于保护社会免受伤害并不理想。

* * *