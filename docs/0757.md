# 什么是后向淘汰？

> 原文:[https://www . javatpoint . com/机器学习中的后向淘汰](https://www.javatpoint.com/backward-elimination-in-machine-learning)

反向消除是建立机器学习模型时的一种特征选择技术。它用于删除那些对因变量或输出预测没有显著影响的特征。在机器学习中有多种方法来建立模型，它们是:

1.  全包
2.  向后消除
3.  预选
4.  双向消除
5.  分数比较

以上是在机器学习中建立模型的可能方法，但我们将只在这里使用反向消除过程，因为它是最快的方法。

### 向后消除的步骤

以下是一些用于应用反向消除过程的主要步骤:

**步骤-1:** 首先，我们需要选择一个显著性水平留在模型中。(SL=0.05)

**步骤 2:** 用所有可能的预测因子/自变量拟合完整的模型。

**步骤 3:** 选择具有最高预测值的预测值，例如。

1.  如果 P 值> SL，转到步骤 4。
2.  否则完成，我们的模型就准备好了。

**第 4 步:**移除该预测值。

**步骤-5:** 用剩余变量重建和拟合模型。

### 需要反向消除:最佳多元线性回归模型:

在前一章中，我们讨论并成功创建了我们的多元线性回归模型，其中我们采用了 **4 个自变量(R & D 支出、行政支出、营销支出和状态(虚拟变量))和一个因变量(利润)**。但是这个模型不是最优的，因为我们已经包括了所有的独立变量，不知道哪个独立模型对预测的影响最大，哪个影响最小。

不必要的特征增加了模型的复杂性。因此，最好只有最重要的特征，并保持我们的模型简单，以获得更好的结果。

因此，为了优化模型的性能，我们将使用向后消除方法。该过程用于优化 MLR 模型的性能，因为它将只包含影响最大的特征，而移除影响最小的特征。让我们开始将其应用于我们的 MLR 模型。

### 反向消除法的步骤:

我们将使用我们在 MLR 的前一章中构建的相同模型。下面是它的完整代码:

```

# importing libraries
import numpy as nm
import matplotlib.pyplot as mtp
import pandas as pd

#importing datasets
data_set= pd.read_csv('50_CompList.csv')

#Extracting Independent and dependent Variable
x= data_set.iloc[:, :-1].values
y= data_set.iloc[:, 4].values

#Catgorical data
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
labelencoder_x= LabelEncoder()
x[:, 3]= labelencoder_x.fit_transform(x[:,3])
onehotencoder= OneHotEncoder(categorical_features= [3])  
x= onehotencoder.fit_transform(x).toarray()

#Avoiding the dummy variable trap:
x = x[:, 1:]

# Splitting the dataset into training and test set.
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.2, random_state=0)

#Fitting the MLR model to the training set:
from sklearn.linear_model import LinearRegression
regressor= LinearRegression()
regressor.fit(x_train, y_train)

#Predicting the Test set result;
y_pred= regressor.predict(x_test)

#Checking the score
print('Train Score: ', regressor.score(x_train, y_train))
print('Test Score: ', regressor.score(x_test, y_test))

```

**从上面的代码中，我们得到的训练和测试集结果为:**

```
Train Score:  0.9501847627493607
Test Score:  0.9347068473282446

```

**两者得分相差 0.0154。**

#### 注意:在这个分数的基础上，我们将在使用向后消除过程后估计特征对我们的模型的影响。

**步骤:1-反向淘汰准备:**

*   **导入库:**首先需要导入 **statsmodels.formula.api** 库，用于 OLS(普通最小二乘法)等各种统计模型的估计。下面是它的代码:

```

import statsmodels.api as smf

```

*   **在特征矩阵中添加一列:**正如我们可以在 MLR 方程(a)中检查到的，有一个常量项 b <sub>0</sub> ，但是这个项在我们的特征矩阵中不存在，所以我们需要手动添加。我们将添加一列，其值为 x <sub>0</sub> = 1，与常量 b <sub>0</sub> 相关联。
    要添加这个，我们将使用**追加 **Numpy** 库的**功能(我们已经将 nm 导入到我们的代码中)，并将赋值 1。下面是它的代码。

```

x = nm.append(arr = nm.ones((50,1)).astype(int), values=x, axis=1)

```

这里我们使用了 axis =1，因为我们想要添加一列。对于添加行，我们可以使用 axis =0。

**输出:**通过执行上面的代码行，一个新的列将被添加到我们的特征矩阵中，它将具有等于 1 的所有值。我们可以通过单击变量资源管理器选项下的 x 数据集来检查它。

![Backward Elimination](../Images/25468d4f43e0b20aa47a857993fc314a.png)

从上面的输出图片中我们可以看到，第一列添加成功，对应的是 MLR 方程的常数项。

**步骤:2:**

*   现在，我们实际上要应用一个反向淘汰过程。首先，我们将创建一个新的特征向量 **x_opt** ，它将只包含一组显著影响因变量的独立特征。
*   接下来，根据后向消除过程，我们需要选择一个显著水平(0.5)，然后需要用所有可能的预测因子来拟合模型。因此为了拟合模型，我们将创建一个新类**的**回归器 _OLS** 对象**OLS**stats models**库。然后我们使用 **fit()** 方法进行拟合。
*   接下来我们需要 **p 值**与 SL 值进行比较，为此我们将使用 **summary()** 方法得到所有值的汇总表。下面是它的代码:

```

x_opt=x [:, [0,1,2,3,4,5]]
regressor_OLS=sm.OLS(endog = y, exog=x_opt).fit()
regressor_OLS.summary()

```

**输出:**通过执行上面几行代码，我们会得到一个汇总表。请看下图:

![Backward Elimination](../Images/a40aaf2b3e9a0bc7882140bcd07b15e2.png)

在上图中，我们可以清楚地看到所有变量的 p 值。这里 **x1、x2 是虚拟变量，x3 是 R & D 支出，x4 是行政支出，x5 是营销支出**。

从表中，我们将选择最高的 p 值，即 x1=0.953。现在，我们有大于 SL 值的最高 p 值，因此将从表中删除 x1 变量(虚拟变量)，并将重新调整模型。下面是它的代码:

```

x_opt=x[:, [0,2,3,4,5]]
regressor_OLS=sm.OLS(endog = y, exog=x_opt).fit()
regressor_OLS.summary()

```

**输出:**

![Backward Elimination](../Images/9c36a9034d1c9f2058dcb9069b474c95.png)

正如我们在输出图像中看到的，现在还剩五个变量。在这些变量中，最高 p 值为 0.961。所以我们将在下一次迭代中移除它。

*   现在 x1 变量的下一个最高值是 0.961，这是另一个伪变量。所以我们将移除它并重新改装模型。下面是它的代码:

```

x_opt= x[:, [0,3,4,5]]
regressor_OLS=sm.OLS(endog = y, exog=x_opt).fit()
regressor_OLS.summary()

```

**输出:**

![Backward Elimination](../Images/9a7fb1e32964ace5f08072b7b362a6da.png)

在上面的输出图像中，我们可以看到虚拟变量(x2)已经被移除。下一个最高值是. 602，它仍然大于. 5，所以我们需要删除它。

*   现在，我们将删除管理支出，这是有 602 值，并再次改装模型。

```

x_opt=x[:, [0,3,5]]
regressor_OLS=sm.OLS(endog = y, exog=x_opt).fit()
regressor_OLS.summary()

```

**输出:**

![Backward Elimination](../Images/648b9520f25c81a7247eca3f92669e43.png)

正如我们在上面的输出图像中看到的，变量(管理开销)已经被移除。不过，还有一个变量，那就是**营销支出**，因为它的 p 值很高 **(0.60)** 。所以我们需要移除它。

*   最后，我们将移除另一个变量，该变量的营销支出 p 值为 0.60，超过了一个显著水平。
    下面是它的代码:

```

x_opt=x[:, [0,3]]
regressor_OLS=sm.OLS(endog = y, exog=x_opt).fit()
regressor_OLS.summary()

```

**输出:**

![Backward Elimination](../Images/f762a1c2632fd68d1eed9c62827ace34.png)

正如我们在上面的输出图像中看到的，只剩下两个变量。所以只有 **R & D 自变量**是预测的显著变量。所以我们现在可以有效地利用这个变量进行预测。

### 评估性能:

在上一个主题中，我们已经计算了模型的训练和测试分数，当我们使用了所有的特征变量时。现在我们将只使用一个特征变量(R&D 花费)来检查分数。我们的数据集现在看起来像:

![Backward Elimination](../Images/49d124edd9d04b1eaa4d5f5d438319e8.png)

**以下是仅使用 R & D 花费建立多元线性回归模型的代码:**

```

# importing libraries
import numpy as nm
import matplotlib.pyplot as mtp
import pandas as pd

#importing datasets
data_set= pd.read_csv('50_CompList1.csv')

#Extracting Independent and dependent Variable
x_BE= data_set.iloc[:, :-1].values
y_BE= data_set.iloc[:, 1].values

# Splitting the dataset into training and test set.
from sklearn.model_selection import train_test_split
x_BE_train, x_BE_test, y_BE_train, y_BE_test= train_test_split(x_BE, y_BE, test_size= 0.2, random_state=0)

#Fitting the MLR model to the training set:
from sklearn.linear_model import LinearRegression
regressor= LinearRegression()
regressor.fit(nm.array(x_BE_train).reshape(-1,1), y_BE_train)

#Predicting the Test set result;
y_pred= regressor.predict(x_BE_test)

#Cheking the score
print('Train Score: ', regressor.score(x_BE_train, y_BE_train))
print('Test Score: ', regressor.score(x_BE_test, y_BE_test))

```

**输出:**

执行上述代码后，我们将获得如下培训和测试分数:

```
Train Score:  0.9449589778363044
Test Score:  0.9464587607787219

```

我们可以看到，训练分数的准确率是 94%，考试分数也是 94%。两个分数相差 **.00149** 。这个分数与之前的分数非常接近，即 **0.0154** ，这里我们已经包含了所有的变量。

**我们只用一个自变量(R & D 花)代替四个变量得到这个结果。因此，现在，我们的模型简单而准确。**

* * *