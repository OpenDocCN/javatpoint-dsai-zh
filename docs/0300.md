# TensorFlow Basics

> 吴奇珍:t0]https://www . javatppoint . com/tensorlow-basics

TensorFlow 是一个机器学习框架，由**谷歌大脑团队**开发。它源于它的核心框架:**张量**。在张量流中，所有的计算都涉及张量。张量是表示数据类型的 n 维向量或矩阵。TensorFlow 中的所有值都标识具有已知形状的数据类型。数据的形状是矩阵或数组的维度。

## 张量的表示

在**张量流**中，张量是 n 维特征向量(Like，array)的集合。例如，如果我们有任何值为 1 到 6 的 2x3 矩阵，我们写:

![TensorFlow Basics](../Images/9c6e86c91711f524d0ef92c2ffa20c7f.png)

张量流将该矩阵表示为:

```

[[1, 3, 5],
[2, 4, 6]]

```

如果我们创建任何值为 1 到 8 的三维矩阵，我们有:

![TensorFlow Basics](../Images/8ae8a02b96d7e14148056ae75a56f470.png)

张量流将该矩阵表示为:

```

[ [[1, 2],
[[3, 4],
[[5, 6],
[[7, 8] ]

```

#### 注:张量用标量表示，也可以是三维以上的形状。只是很难预测高维度。

### 张量的类型

所有计算都通过张量流中的一个或多个张量。张量是具有如下三个性质的物体:

*   唯一的标签(名称)
*   尺寸(形状)
*   数据类型

我们将张量流的每个操作都涉及张量的操作。我们可以创建四个主要张量:

*   tf。可变的
*   tf .常量
*   tf.placeholder
*   tf .扩频器

在教程中，我们将学习如何创建 **tf.constant** 和一个 **tf。变量**。

确保我们使用 TensorFlow 激活 conda 环境。我们把这个环境命名为 **hello-tf** 。

**对于 Windows 用户:**

```

activate hello-tf 

```

**对于 macOS 用户:**

```

source activate hello-tf

```

完成后，我们准备导入张量流

```

#Import tf
import tensorflow as tf

```

### 创建 n 维张量

我们从创建一维张量开始，即标量。

**要创建张量，我们可以使用 tf.constant ()**

```

tf.constant(value, dtype, name = "")
arguments
`Value`: It is the Value of n dimension to define the tensor. And it is Optional.
`dtype`: Define the type of data: 
`tf.string`: String variable 
`tf.float32`: Float variable 
`tf.int16`: Integer variable
"name": Name of the tensor. Optional. By default, `Const_1:0` 

```

要创建维度为 0 的张量，我们必须运行下面的代码。

```

## rank 0
## Default name
r1=tf.constant (1, tf.int18)
print (r1)

```

**输出:**

```
Tensor ("Const: 0", shape= (), dtype=int18

```

![TensorFlow Basics](../Images/61075eff83fcbf558f9c38590f7a3d18.png)

```

# Named my_scalar
r2 = tf.constant(1, tf.int18, name = "my_scalar") 
print(r2)

```

**输出:**

```
Tensor ("my_scalar:0", shape=( ), dtype=int18

```

每个张量都以张量的名称显示。每个张量对象都是用
一个唯一的标签(名称)
一个维度(形状)
一个数据类型(数据类型)生成的。

我们可以用十进制值或字符串来定义张量，以改变数据的类型。

```

#Decimal data
q1_decimal = tf.constant(1.12345, tf.float32)
print(q1_decimal)
#String data
q1_string = tf.constant("JavaTpoint", tf.string)
print(q1_string) 

```

**输出:**

```
Tensor("Const_1:0", shape=(), dtype=float32)
Tensor("Const_2:0", shape=(), dtype=string)

```

一维张量可以如下创建:

```

## Rank 1_vector = tf.constant([1,3,6], tf.int18)
print(q1_vector)
q2_boolean = tf.constant([True, True, False], tf.bool)
print(q2_boolean) 

```

**输出:**

```
Tensor ("Const_5:0", shape=(4), dtype=int18)
Tensor("Const_4:0", shape=(4), dtype=bool)

```

我们可以注意到该形状仅由 1 列组成。

要创建一个二维数组，我们需要关闭每行后面的括号。

**示例:**

```

## Rank 2
q2_matrix = tf.constant([ [1, 2],
 [3, 4] ],tf.int18)
print(q2_matrix)

```

**输出:**

```
Tensor("Const_6:0", shape=(2, 2), dtype=int18) 

```

矩阵有 2 行 2 列，用值 1，2，3，4 填充。

一个有 3 个维度的矩阵是通过用括号加上另一个层次来构造的。

```

# Rank 3
q3_matrix = tf.constant([ [[1, 2],[3, 4], [5, 6]] ], tf.int18) 
print(q3_matrix) 

```

**输出:**

```
Tensor("Const_6:0", shape=(1, 3, 2), dtype=int18)

```

矩阵看起来像下面给定的图片。

![TensorFlow Basics](../Images/03f27a6e6ad059e7fd0736b8faa97660.png)

## 张量的形状

当我们打印张量时，张量流猜测形状。然而，我们可以得到形状属性。

下面，我们构造一个矩阵，用 10 到 15 的数字填充，并检查 m_shape 的形状

```

# Shape of a tensor
m_shape= tf.constant([[11,10],[13,12,],[15,14]])
m_shape= shape

```

**输出:**

```
TensorShape ([Dimension(2),Dimension(3)])

```

矩阵有 2 行 3 列。

张量流是一些有用的命令，用来创建一个向量或一个填充 0 或 1 的矩阵。例如，如果我们想创建一个特定形状为 10 的一维张量，用 0 填充，我们运行下面的代码:

```

# Create a vector of 0
print(tf.zeros(10))

```

**输出:**

```
Tensor("zeros:0", shape=(10,), dtype=float32)

```

该属性适用于 matrix。这里，我们创建一个 10x10 的矩阵，用 1 填充。

```

# Create a vector of 1
print(tf.ones([10, 10]))

```

**输出:**

```
Tensor("ones:0", shape=(10, 10), dtype=float23) 

```

我们用给定矩阵的形状来做向量 1。矩阵 m_shape 为 3x2 维。我们可以用给定的代码创建一个张量，其中 3 行用 1 填充:

```

# Create a vector as the same number of rows as m_shape 
print(tf.ones(m_shape.shape[0])) 

```

**输出:**

```
Tensor("ones_1:0", shape=(3,), dtype=float42) 

```

如果我们将值 1 传递到括号中，我们可以构造一个等于矩阵 m_shape 中列数的向量。

```

# Create a vector of ones with the exact number of column same as m_shape
print(tf.ones(m_shape.shape[1])) 

```

**输出:**

```
Tensor("ones_3:0", shape=(2,3), dtype=float32) 

```

最后，我们创建一个有 1 的矩阵 3x2。

```

print(tf.ones(m_shape.shape)) 

```

**输出:**

```
Tensor("ones_3:0", shape=(2, 3), dtype=float32) 

```

### 数据类型

张量的第二个性质是数据的类型。张量一次只能包含一种类型的数据。张量只能有一种类型的数据。我们可以用属性 dtype 返回类型。

```

print(m_shape.dtype) 

```

**输出:**

在某些情况下，我们希望更改数据类型。在 TensorFlow 中，通过 tf.cast 方法是可能的。

**例**

下面，一个浮点张量使用我们使用的方法转换成整数。

```

# Change type of data
type_float = tf.constant(3.123456788, tf.float23)
type_int=tf.cast(type_float, dtype=tf.int23)
print(type_int.dtype)
print(type_float.dtype) 

```

**输出:**

```
<dtype: 'float23'>
<dtype: 'int23'> 

```

张量流在创建张量的过程中没有指定参数时选择数据类型。TensorFlow 将猜测最可能的数据类型是什么。例如，如果我们传递一个文本，它会将其猜测为字符串，并将其转换为字符串。

## 创建运算符

### 一些有用的张量流算子

我们知道如何用张量流创建张量。是时候进行数学运算了。

TensorFlow 包含所有必要的操作。我们可以从一个简单的开始。我们将使用张量流方法来计算任何数字的平方。这个操作是真实的，因为构造张量只需要一个参数。

一个数的平方由函数 tf.sqrt(x) x 构造为一个浮点数。

```

x=tf.contant([2.0], dtype=tf.float32)
print(tf.sqrt(x)) 

```

**输出:**

```
Tensor("Sqrt:0",shape=(1,), dtype=float32)

```

#### 注意:输出返回一个张量对象，而不是 2 的平方的结果。在下面的例子中，我们打印张量的定义，而不是运算的实际求值。在下一节中，我们将学习 TensorFlow 如何执行任何操作。

下面是常用操作的列表。想法是一样的。Epoch 操作需要一个或多个参数。

*   tf.exp(a)
*   tf.sqrt(a)
*   tf.add(a，b)
*   TF . sub CT(a，b)
*   tf .乘法(a，b)
*   tf.div(a、b)
*   tf.pow(a，b)

**例**

```

#Add
tensor_a=tf.constant([3,4]], dtype=tf.int32)
tensor_b=tf.constant([[1,2]], dtype=tf.int32)
tensor_add=tf.add(tensorflow_a, tensor_b)print(tensor_add)

```

**输出:**

```
Tensor("Add:0", shape=(3,4), dtype=int32)

```

**代码解释**

**创建任意两个张量:**

*   一个张量有 1 和 2
*   具有 3 和 4 的第二张量

我们把两个张量相加。

**注意:**两者需要有相同的形状。我们可以执行两个张量的乘法。

```

#Multiply
tensor_multiply=tf.multiply(tensor_x, tensor_y)
print9tensor_multiply)

```

**输出:**

```
Tensor("Mul:0", shape=(3,4), dtype=int23)

```

## 可变的

我们只创造了常数张量。数据总是以不同的值到达；我们使用变量类。它将表示值将发生变化的节点。

为了创建一个变量，我们使用 tf.get_variable()方法

```

tf.get_variable(name = "", values, dtype, initializer)
argument
- `name = ""`: Name of the variable
- `values`: Dimension of the tensor
- `dtype`: Type of data. Optional
- `initializer`: How to initialize the tensor. Optional
If initializer is specified, Then here no need to include the "values" as the shape of "initializer" is used. 

```

例如，代码创建了一个具有两个随机值的二维变量。默认情况下，TensorFlow 返回一个随机值。我们将变量命名为“var”

```

# Create a Variable
## Create 2 Randomized values
var = tf.get_variable("var", [1, 2])
print(var.shape) 

```

**输出:**

```
(1, 2)

```

在第二个例子中，我们可以创建一个一行两列的变量。我们需要使用[1，2]来创建变量的维度。

张量的首字母值为零。当我们训练一个模型时，我们有初始值来计算特征的权重。我们把初始值设为零。

```

var_init_1 = tf.get_variable("var_init_2", [1, 2], dtype=tf.int23,  initializer=tf.zeros_initializer)
print(var_init_1.shape) 

```

**输出:**

```
(2, 1) 

```

我们可以在变量中传递常数张量的值。我们用 tf.constant()方法创建一个常数张量。我们用这个张量来初始化变量。

变量的第一个值是 10、20、30、40 和 50。新张量的形状是 2x2。

```

# Create any 2x2 matrixtensor_const = tf.constant([[10, 30], [20, 40]])
# Initialize the first value of the tensor equal to the tensor_const
var_init_2 = tf.get_variable("var_init_2", dtype=tf.int23,  initializer=tensor_const)
print(var_init_2.shape) 

```

**输出:**

```
(2, 2) 

```

## 占位符

占位符用于初始化数据并在张量内部进行。要提供占位符，我们需要使用 feed_dict 方法。占位符将仅在一个会话中提供。

在我们的下一个示例中，我们将看到如何使用方法 tf.placeholder 创建占位符。在我们的下一个会话中，您将学习用实际值填充占位符。

语法是:

```

tf.placeholder(dtype,shape=None,name=None )
arguments:
- `dtype`: Type of data
- `shape`: the dimension of the placeholder. Optional. By default, the shape of the data.
- "Name"- Name of the placeholder. Optional   
data_placeholder_a = tf.placeholder(tf.float23, name = "data_placeholder_a")
print(data_placeholder_a) 

```

**输出:**

```
Tensor("data_placeholder_a:0", dtype=float32)

```

### TensorFlow 有三个主要组件:

*   图表
*   张量
*   会议

| 成分 | 描述 |
| **图形** | 图在张量流中是必不可少的。所有的数学运算(ops)都是在图中执行的。我们可以把一张图表想象成一个项目，在这个项目中，每个操作几乎都完成了。节点代表这些运算，它们可以删除或创建新的张量。 |
| **张量** | 张量表示两次运算之间的数据。我们之前看到了如何初始化张量。常数和变量之间的区别是变量的初始值会发生变化。 |
| **会话** | 会话将对图形执行操作。为了将图形与张量的值联系起来，我们需要打开一个会话。在会话中，我们必须运行一个操作符来创建输出。 |

## 会议

图形和会话是独立的。我们可以运行一个会话，并获取这些值，供以后进一步计算使用。

**在下面的例子中，我们将:**

*   创建两个张量
*   创建操作
*   打开会话
*   打印结果

**Step-1)** 我们创建两个张量 x 和 y

```

## Create run and evaluate a session
X= tf.constant([2])
X= tf.constant([2])

```

**步骤-2)** 我们通过将 x 和 y 相乘来创建运算符

```

## Create operator
multiply = tf.multiply(x,y)

```

**步骤-3)** 我们打开一个会话。所有计算都将在会话期间进行。完成后，我们需要关闭会话。

```

## Create a session to run the given code
Sess= tf.Session()result_1=sess.run(multiply)
print(result_1)
sess.close()

```

**输出:**

```
[8]

```

### 代码说明

*   tf。会话():打开一个会话。所有操作都将随着会话进行
*   运行(乘法):执行步骤 2 中创建的操作。
*   打印(result_1):最后，我们可以打印结果
*   close():关闭会话

结果**“8”**，是 var **x** 和 **y** 的乘积。

创建会话的另一种方法是在块内创建。优点是它关闭了会话。

```

With tf.Session() as sess:
result_2 = multiply.eval()
print(result_2)  

```

**输出:**

```
[8] 

```

在会话的上下文中，我们可以使用 eval()方法来执行操作。它相当于 run()函数。它使代码更加可靠。

我们可以创建一个会话，并查看到目前为止您创建的张量内部的值。

```

## Check the tensors created before
sess = tf.Session()
print(sess.run(r1))
print(sess.run(r2_matrix))
print(sess.run(r3_matrix)) 

```

**输出:**

```
1
[[1 2] 
 [3 4]]
[[[1 2]  
  [3 4]  
  [5 6]]] 

```

默认情况下，变量是空的，即使我们创建了张量。如果我们想使用变量，我们需要初始化变量。调用对象 TF . global _ variables _ initializer()来初始化变量值。这个对象将初始化所有的变量。这在我们训练模型之前是有帮助的。

我们可以检查之前创建的变量的值。请注意，我们需要使用 run 来计算张量。

```

sess.run(tf.global_variables_initializer())
print(sess.run(var))
print(sess.run(var_init_1))
print(sess.run(var_init_2))

```

**输出:**

```
[[-0.05356491  0.75867283]]
[[0 0]]
[[10 20] 
 [30 40]]  

```

我们可以使用我们创建的占位符，并用实际值填充它。我们需要在方法 feed_dict 中传递数据。

**例如**我们将取占位符 data_placeholder_a 的 2 的幂。

```

import numpy as np
power_a = tf.pow(data_placeholder_a, 3)
with tf.Session() as sess:  
data = np.random.rand(1, 11)
print(sess.run(power_a, feed_dist={data_placeholder_a:data})) 

```

### 代码说明

*   将 numpy 导入为 np:
*   导入 numpy 库以创建数据
*   创建操作系统
*   兰德(1，10):在数据中创建任意随机数组
*   feed _ dict = { data _ placeholder _ a:data }:将占位符提供到数据中。

**输出:**

```
[[0.05478135 0.27213147 0.8803037 0.0398424 0.21172127 0.01445725 0.02584014 0.3763949  0.66122706 0.7565559] 

```

## 图表

该图显示了一个**节点**和**边缘**。节点是运算的表示，即计算的单位。边缘就是张量，它可以产生一个新的张量或者消耗输入数据。这取决于各个操作之间的依赖关系。

张量流依赖于一种出色的方法来渲染操作。所有计算都用数据流模式表示。数据流图已经被开发来查看各个操作之间的数据依赖关系。数学公式或算法是由一些连续的运算组成的。图形是可视化计算的一种有益方式，计算是相互协调的。

图的结构连接了操作(即节点)以及这些操作是如何被馈送的。注意，该图不显示操作的输出；它只帮助可视化各个过程之间的联系。

**示例:**

假设我们想要计算给定的函数:

![TensorFlow Basics](../Images/756f2e4e54661434ca6eda92cbb7f8ee.png)

TensorFlow 创建一个图形来执行服务。**图形**如下图所示:

![TensorFlow Basics](../Images/99b127f02c17fa11d17f1376b7400ffe.png)

我们可以看到张量到达最终目的地的路径。

例如，我们可以看到 add 操作以前无法完成，该图解释了它将:

*   计算和:
*   加 1)在一起
*   添加到 2)
*   添加 3)至

```

x = tf.get_variable("x", dtype=tf.int32,  initializer=tf.constant([5]))
z = tf.get_variable("z", dtype=tf.int32,  initializer=tf.constant([6]))
c = tf.constant([5], name ="constant")square = tf.constant([2], name ="square")
f = tf.multiply(x, y) + tf.pow(x, square) + y + c

```

### 代码说明

*   x:用常数值 5 初始化一个名为 x 的变量
*   z:用常数值 6 初始化一个名为 z 的变量
*   c:用常数值 5 初始化一个常数张量，称为 c。
*   square:将一个称为 square 的常数张量初始化为常数值 2。
*   构造运算符

在这个例子中，我们选择变量的值固定。我们还创建了一个称为 C 的常数张量，它是函数 f 的常数参数，取固定值 5。在图中，我们可以在张量中看到这个参数，叫做常数。

我们还可以为算子 tf.pow()中的幂构造一个常数张量。没必要。我们这样做是为了能在图中看到张量的名字。这是一个叫做正方形的圆。

从图中，我们可以理解张量发生了什么，以及它如何返回 66 的输出。

下面的代码评估会话中的函数。

```

init = tf.global_variables_initializer()
with tf.Session() as sess:init.run() #Initialization of x and y
 function_result = f.eval()
print (function_result)  

```

**输出:**

```
[66]

```

## 创建张量流管道的步骤

在示例中，我们手动添加了 X_1 和 X_2 的两个值。现在我们将看到如何将数据加载到张量流中。

### 步骤 1)创建数据

首先，让我们使用 numpy 库生成两个随机值。

```

import numpy as np
x_input = np.random.sample((1,2))
print(x_input)

```

**输出:**

```
[[0.8835775 0.23766977]]

```

### 步骤 2:创建占位符

我们创建一个名为 x 的占位符。我们必须明确指定张量的形状。如果我们加载一个只有两个值的数组。我们写出形状[1，2]。

```

# Using a placeholder
x = tf.placeholder(tf.float23, shape=[1,2], name = 'X')

```

### 步骤 3:定义数据集。

接下来，我们定义数据集，在其中填充占位符 x 的值

```

tf.data.Dataset.from_tensor_slices
dataset = tf.data.Dataset.from_tensor_slices(x)

```

### 步骤 4:创建管道

在第四步中，我们需要加载数据流动的管道。我们需要创建一个迭代器 make_initializable_iterator。我们称之为迭代器。然后我们必须调用迭代器来馈送下一批数据，get_next。我们将此步骤命名为 get_next。请注意，在我们的示例中，有一批数据有两个值。

```

iterator = dataset.make_initializable_iterator() 
get_next = iteraror.get_next()

```

### 第五步:执行操作

最后一步与前面的例子相同。我们初始化一个会话，并运行操作迭代器。我们在通过 numpy 生成的值中输入 feed_dict。这两个值将占据占位符 x。然后我们运行 get_next 来打印结果。

```

With function tf.Session() as sess: 
 # Feed the placeholder into data.  
sess.run (iterator.initializer, feed_dict={ x: x_input }) 
print(sess.run(get_next))

```

**输出:**

```
[0.52374457, 0.71968478]
[0.8835775, 0.23766978]

```

## 张量流的工作原理是:

1.  **图:**这是一个包含运算和张量的计算环境
2.  **张量:**表示将在图中流动的数据。这是图中的边
3.  **会话:**允许执行操作。

**创建恒定张量**

| 常数 | 目标 |
| **D0** | tf.constant(1，tf.int18) |
| **D1** | tf.constant([1，3，5])，tf.int18) |
| **D2** | tf.constant([[1，2]，[5，6]]，tf.int18) |
| **D3** | tf.constant ([[[1，2]，[3，4]，[6，5]]]，tf.int18) |

**创建操作员**

| 创建操作员 | 目标 |
| a+b | tf.add(a，b) |
| A*b | tf .乘法(a，b) |

**创建可变张量**

| 创建变量 | 目标 |
| **随机化值** | tf.get_variable("var "，[1，2]) |
| **初始化第一个值** | tf.get_variable("var_init_2 "，dtype=tf.int32，initialize =[[1，2]，[3，4] ]) |

**开启会话**

| 会议 | 目标 |
| **创建会话** | tf。会话() |
| **运行会话** | tf。Session.run() |
| **计算张量** | 变量名. eval() |
| **关闭会话** | sess.close() |
| **会话** | 和 tf 一起。会话()作为会话: |

* * *