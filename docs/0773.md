# 机器学习中的 Apriori 算法

> 原文:[https://www . javatpoint . com/apriori-机器学习中的算法](https://www.javatpoint.com/apriori-algorithm-in-machine-learning)

Apriori 算法使用频繁项集来生成关联规则，它是为处理包含事务的数据库而设计的。在这些关联规则的帮助下，它决定了两个对象的联系有多强或多弱。该算法使用**广度优先搜索**和**哈希树**来高效计算项目集关联。它是从大数据集中寻找频繁项集的迭代过程。

这个算法是由 **1994** 年的 **R .阿格沃尔**和**斯里坎特**给出的。主要用于*菜篮子分析*，帮助找到那些可以一起买的产品。它还可以用于医疗保健领域，为患者发现药物反应。

**什么是频繁项集？**

频繁项目集是那些支持度大于阈值或用户指定的最小支持度的项目。这意味着如果 A & B 一起是频繁项集，那么单独的 A 和 B 也应该是频繁项集。

假设有两个事务:A= {1，2，3，4，5}，B= {2，3，7}，在这两个事务中，2 和 3 是频繁项集。

#### 注意:为了更好的理解 apriori 算法，以及支持度、置信度等相关术语，建议理解关联规则学习。

### 先验算法的步骤

以下是 apriori 算法的步骤:

**步骤-1:** 确定事务数据库中项目集的支持度，选择最小支持度和置信度。

**第 2 步:**取交易中支持值高于最小或选定支持值的所有支持。

**步骤-3:** 找出这些子集中置信度值高于阈值或最小置信度的所有规则。

**第 4 步:**按照升降的降序排列规则。

### Apriori 算法正在运行

我们将通过一个例子和数学计算来理解 apriori 算法:

**示例:**假设我们有下面这个数据集，它有各种各样的事务，从这个数据集，我们需要找到频繁项集，并使用 Apriori 算法生成关联规则:

![Apriori Algorithm in Machine Learning](../Images/40e46db608864e64d43fed32e208501b.png)

### 解决方案:

### 第一步:计算 C1 和 L1:

*   在第一步中，我们将创建一个表，该表包含给定数据集中每个项目集的支持计数(数据集中每个项目集单独出现的频率)。该表被称为 C1 的**候选集。**
    ![Apriori Algorithm in Machine Learning](../Images/e199bdebf772a15365d0a1ce3b0c4b79.png)
*   现在，我们将取出支持计数大于最小支持(2)的所有项目集。它将为我们提供 L1**频繁项目集的表。**
    由于除 E 外，所有的项集都具有大于或等于最小支持的支持计数，因此 E 项集将被移除。
    ![Apriori Algorithm in Machine Learning](../Images/1311df11b6c0fbfd080bdc8ad53fb084.png)

### 第二步:候选一代 C2 和 L2:

*   在这一步中，我们将在 L1 的帮助下创造 C2。在 C2，我们将以子集的形式创建 L1 的项目集对。
*   创建子集后，我们将再次从数据集的主事务表中找到支持计数，即这些对在给定的数据集中一起出现了多少次。因此，我们将得到 C2 的下表:
    ![Apriori Algorithm in Machine Learning](../Images/b88b4bbf68c36752b0774a3c3674e70c.png)
*   同样，我们需要将 C2 支持计数与最小支持计数进行比较，比较后，支持计数较少的项目集将从 C2 表中删除。它将为我们提供 L2 的下表
    ![Apriori Algorithm in Machine Learning](../Images/9e6d2fa6318e1e55bef0717d8b26dc5e.png)

### 步骤 3:候选人生成 C3，L3:

*   对于 C3，我们将重复同样的两个过程，但是现在我们将使用三个项目集的子集一起形成 C3 表，并将从数据集计算支持计数。它会给出下表:
    ![Apriori Algorithm in Machine Learning](../Images/ca6c3da36ae66f3ce8b60dcd06e3c1db.png)
*   现在我们将创建 L3 表。从上面的 C3 表中我们可以看到，只有一个支持计数等于最小支持计数的项目集组合。所以，L3 将只有一个组合，即 **{A，B，C}。**

### 步骤 4:找到子集的关联规则:

要生成关联规则，首先，我们将创建一个新表，其中包含已发生组合{A，B.C}的可能规则。对于所有规则，我们将使用公式 **sup( A ^B)/A.** 计算置信度。在计算所有规则的置信度值后，我们将排除置信度低于最小阈值(50%)的规则。

考虑下表:

| 规则 | 支持 | 信心 |
| A ^B → C | Two | sup {(^b)^c}/sup(a ^b)= 2/4 = 0.5 = 50% |
| B^C → A | Two | sup {(b ^ c)^ a }/sup(b ^ c)= 2/4 = 0.5 = 50% |
| A^C → B | Two | sup {(^c)^b}/sup(a ^c)= 2/4 = 0.5 = 50% |
| C→ A ^B | Two | sup {(c ^(a ^ b)}/sup(c)= 2/5 = 0.4 = 40% |
| A→ B^C | Two | sup{(a^( b ^c)}/sup(a)= 2/6 = 0.33 = 33.33% |
| B→ B^C | Two | sup {(b ^(b ^ c)}/sup(b)= 2/7 = 0.28 = 28% |

由于给定的阈值或最小置信度为 50%，因此前三个规则 **A ^B → C、B^C → A 和 A^C → B** 可以被认为是给定问题的强关联规则。

### Apriori 算法的优势

*   这是容易理解的算法
*   该算法的连接和删减步骤可以很容易地在大数据集上实现。

### Apriori 算法的缺点

*   与其他算法相比，apriori 算法运行缓慢。
*   当它多次扫描数据库时，整体性能可能会降低。
*   apriori 算法的时间复杂度和空间复杂度都是 O(2 <sup>D</sup> ，非常高。这里 D 代表数据库中存在的水平宽度。

### Apriori 算法的 Python 实现

现在我们将看到 Apriori 算法的实际实现。为了实现这一点，我们有一个零售商的问题，他想找到他的商店的产品之间的关联，这样他就可以向他的客户提供“买这个，得到那个”的报价。

零售商有一个数据集信息，其中包含客户进行的交易列表。在数据集中，每行显示客户购买的产品或客户进行的交易。为了解决这个问题，我们将执行以下步骤:

*   **数据预处理**
*   **在数据集上训练 Apriori 模型**
*   **可视化结果**

### 1.数据预处理步骤:

第一步是数据预处理步骤。在这种情况下，首先，我们将执行库的导入。这方面的代码如下:

*   **导入库:**

在导入库之前，我们将使用下面一行代码来安装 ***apyori 包*** 以进一步使用，因为 Spyder IDE 不包含它:

```

pip install apyroi

```

下面是实现将用于模型不同任务的库的代码:

```

import numpy as nm
import matplotlib.pyplot as mtp
import pandas as pd

```

*   **导入数据集:**
    现在，我们将为我们的先验模型导入数据集。要导入数据集，这里会有一些更改。数据集的所有行都显示了客户进行的不同交易。第一行是第一个客户完成的交易，这意味着每个列没有特定的名称，并且有自己的单独值或产品详细信息(参见下面代码后给出的数据集)。因此，我们需要在代码中提到，这里没有指定头。代码如下:

```

#Importing the dataset
dataset = pd.read_csv('Market_Basket_data1.csv')
transactions=[]
for i in range(0, 7501):
    transactions.append([str(dataset.values[i,j])  for j in range(0,20)])

```

在上面的代码中，第一行显示了将数据集导入熊猫格式。使用代码的第二行是因为我们将用于训练模型的 apriori()采用事务列表格式的数据集。因此，我们创建了一个事务的空列表。该列表将包含从 0 到 7500 的所有项目集。这里我们取了 7501，因为在 [Python](https://www.javatpoint.com/python-tutorial) 中，没有考虑最后一个索引。

数据集如下图所示:

![Apriori Algorithm in Machine Learning](../Images/0aeee4217944b35da4dbfec1273c4ac7.png)

### 2.在数据集上训练先验模型

为了训练模型，我们将使用从 **apyroi** 包导入的**先验函数**。该函数将返回**规则**在数据集上训练模型。考虑下面的代码:

```

from apyori import apriori
rules= apriori(transactions= transactions, min_support=0.003, min_confidence = 0.2, min_lift=3, min_length=2, max_length=2)

```

在上面的代码中，第一行是导入 apriori 函数。在第二行，apriori 函数返回规则的输出。它采用以下参数:

*   **交易**:交易列表。
*   **最小支持** =设置最小支持浮动值。这里我们使用了 0.003，它是通过每个客户每周进行 3 次交易来计算交易总数的。
*   **最小置信度**:设置最小置信度值。这里我们取了 0.2。可以根据业务问题进行更改。
*   **最小提升** =设置最小提升值。
*   **min_length** =关联需要的产品数量最少。
*   **max_length** =取关联最大产品数。

### 3.可视化结果

现在我们将可视化先验模型的输出。在这里，我们将遵循下面给出的更多步骤:

*   **显示先验函数**产生的规则结果

```

results= list(rules)
results	

```

通过执行上面几行代码，我们将得到 9 条规则。考虑以下输出:

**输出:**

```
[RelationRecord(items=frozenset({'chicken', 'light cream'}), support=0.004533333333333334, ordered_statistics=[OrderedStatistic(items_base=frozenset({'light cream'}), items_add=frozenset({'chicken'}), confidence=0.2905982905982906, lift=4.843304843304844)]),
 RelationRecord(items=frozenset({'escalope', 'mushroom cream sauce'}), support=0.005733333333333333, ordered_statistics=[OrderedStatistic(items_base=frozenset({'mushroom cream sauce'}), items_add=frozenset({'escalope'}), confidence=0.30069930069930073, lift=3.7903273197390845)]),
 RelationRecord(items=frozenset({'escalope', 'pasta'}), support=0.005866666666666667, ordered_statistics=[OrderedStatistic(items_base=frozenset({'pasta'}), items_add=frozenset({'escalope'}), confidence=0.37288135593220345, lift=4.700185158809287)]),
 RelationRecord(items=frozenset({'fromage blanc', 'honey'}), support=0.0033333333333333335, ordered_statistics=[OrderedStatistic(items_base=frozenset({'fromage blanc'}), items_add=frozenset({'honey'}), confidence=0.2450980392156863, lift=5.178127589063795)]),
 RelationRecord(items=frozenset({'ground beef', 'herb & pepper'}), support=0.016, ordered_statistics=[OrderedStatistic(items_base=frozenset({'herb & pepper'}), items_add=frozenset({'ground beef'}), confidence=0.3234501347708895, lift=3.2915549671393096)]),
 RelationRecord(items=frozenset({'tomato sauce', 'ground beef'}), support=0.005333333333333333, ordered_statistics=[OrderedStatistic(items_base=frozenset({'tomato sauce'}), items_add=frozenset({'ground beef'}), confidence=0.37735849056603776, lift=3.840147461662528)]),
 RelationRecord(items=frozenset({'olive oil', 'light cream'}), support=0.0032, ordered_statistics=[OrderedStatistic(items_base=frozenset({'light cream'}), items_add=frozenset({'olive oil'}), confidence=0.20512820512820515, lift=3.120611639881417)]),
 RelationRecord(items=frozenset({'olive oil', 'whole wheat pasta'}), support=0.008, ordered_statistics=[OrderedStatistic(items_base=frozenset({'whole wheat pasta'}), items_add=frozenset({'olive oil'}), confidence=0.2714932126696833, lift=4.130221288078346)]),
 RelationRecord(items=frozenset({'pasta', 'shrimp'}), support=0.005066666666666666, ordered_statistics=[OrderedStatistic(items_base=frozenset({'pasta'}), items_add=frozenset({'shrimp'}), confidence=0.3220338983050848, lift=4.514493901473151)])]

```

我们可以看到，上面的输出是不容易理解的形式。因此，我们将以合适的格式打印所有规则。

*   **以更清晰的方式可视化规则、支持、信心、提升:**

```

for item in results:
    pair = item[0] 
    items = [x for x in pair]
    print("Rule: " + items[0] + " -> " + items[1])

    print("Support: " + str(item[1]))
    print("Confidence: " + str(item[2][0][2]))
    print("Lift: " + str(item[2][0][3]))
    print("=====================================")

```

**输出:**

通过执行上面的代码行，我们将得到下面的输出:

```
Rule: chicken -> light cream
Support: 0.004533333333333334
Confidence: 0.2905982905982906
Lift: 4.843304843304844
=====================================
Rule: escalope -> mushroom cream sauce
Support: 0.005733333333333333
Confidence: 0.30069930069930073
Lift: 3.7903273197390845
=====================================
Rule: escalope -> pasta
Support: 0.005866666666666667
Confidence: 0.37288135593220345
Lift: 4.700185158809287
=====================================
Rule: fromage blanc -> honey
Support: 0.0033333333333333335
Confidence: 0.2450980392156863
Lift: 5.178127589063795
=====================================
Rule: ground beef -> herb & pepper
Support: 0.016
Confidence: 0.3234501347708895
Lift: 3.2915549671393096
=====================================
Rule: tomato sauce -> ground beef
Support: 0.005333333333333333
Confidence: 0.37735849056603776
Lift: 3.840147461662528
=====================================
Rule: olive oil -> light cream
Support: 0.0032
Confidence: 0.20512820512820515
Lift: 3.120611639881417
=====================================
Rule: olive oil -> whole wheat pasta
Support: 0.008
Confidence: 0.2714932126696833
Lift: 4.130221288078346
=====================================
Rule: pasta -> shrimp
Support: 0.005066666666666666
Confidence: 0.3220338983050848
Lift: 4.514493901473151
=====================================

```

从上面的输出，我们可以分析每个规则。第一条规则是**淡奶油→鸡肉**，规定淡奶油和鸡肉是大多数顾客经常购买的。这个规则的支持率是 **0.0045，**，信心是 **29%。**因此，如果顾客购买淡奶油，他也购买鸡肉的概率为 29%，并且在交易中出现了 0.0045 次。我们也可以在其他规则中检查所有这些内容。

* * *