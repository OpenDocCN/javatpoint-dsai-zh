# 机器学习中的交叉验证

> 原文:[https://www . javatpoint . com/机器学习中的交叉验证](https://www.javatpoint.com/cross-validation-in-machine-learning)

交叉验证是一种通过在输入数据子集上对模型进行训练并在之前未见过的输入数据子集上进行测试来验证模型效率的技术。 ***我们也可以说这是一种检验统计模型如何泛化为独立数据集的技术*** 。

在[机器学习](https://www.javatpoint.com/machine-learning)中，总是需要测试模型的稳定性。意味着只基于训练数据集；我们无法在训练数据集上拟合我们的模型。为此，我们保留了数据集的一个特定样本，它不是训练数据集的一部分。之后，在部署之前，我们在该示例上测试我们的模型，并且这个完整的过程将接受交叉验证。这与一般的列车测试分割不同。

因此，交叉验证的基本步骤是:

*   保留数据集的子集作为验证集。
*   使用训练数据集向模型提供训练。
*   现在，使用验证集评估模型性能。如果模型在验证集上表现良好，执行下一步，否则检查问题。

## 用于交叉验证的方法

交叉验证有一些常用的方法。这些方法如下:

1.  **验证集方法**
2.  **遗漏交叉验证**
3.  **省去一个交叉验证**
4.  **K 折交叉验证**
5.  **分层 k 倍交叉验证**

### 验证集方法

我们将输入数据集分成训练集和验证集方法中的测试或验证集。两个子集都有 50%的数据集。

但是它有一个很大的缺点，那就是我们只是使用 50%的数据集来训练我们的模型，所以模型可能会错过捕获数据集的重要信息。它也倾向于给出供给不足的模型。

### 遗漏交叉验证

在这种方法中，p 数据集被排除在训练数据之外。这意味着，如果原始输入数据集中总共有 n 个数据点，那么 n-p 个数据点将用作训练数据集，p 个数据点将用作验证集。对所有样本重复这一完整过程，计算平均误差，以了解模型的有效性。

这种技术有一个缺点；也就是说，对于大 p 来说，计算可能很困难。

### 省去一个交叉验证

这种方法类似于 leave-p-out 交叉验证，但是我们需要从训练中取出 1 个数据集来代替 p。这意味着，在这种方法中，对于每个学习集，只保留一个数据点，剩下的数据集用于训练模型。这个过程对每个数据点重复进行。因此，对于 n 个样本，我们得到 n 个不同的训练集和 n 个测试集。它具有以下特点:

*   在这种方法中，偏差最小，因为使用了所有数据点。
*   该过程执行 n 次；因此执行时间很长。
*   当我们针对一个数据点进行迭代检查时，这种方法会导致在测试模型有效性时出现很大的差异。

### 多重交叉验证

K 重交叉验证方法将输入数据集分成 K 组大小相等的样本。这些样品被称为**褶皱**。对于每个学习集，预测函数使用 k-1 个折叠，其余的折叠用于测试集。这种方法是一种非常流行的 CV 方法，因为它很容易理解，并且输出比其他方法更少偏向。

k 倍交叉验证的步骤是:

*   将输入数据集分成 K 个组
*   对于每组:
    *   取一组作为储备或测试数据集。
    *   使用剩余组作为训练数据集
    *   在训练集上拟合模型，并使用测试集评估模型的性能。

让我们举一个 5 倍交叉验证的例子。因此，数据集被分成 5 个折叠。在 1 <sup>st</sup> 迭代中，保留第一个折叠用于测试模型，其余部分用于训练模型。在第二次<sup>和第三次</sup>迭代中，第二次折叠用于测试模型，其余的用于训练模型。这一过程将继续，直到每个文件夹都不用于测试文件夹。

考虑下图:

![Cross-Validation in Machine Learning](../Images/ddb5dc274ed804e34a361114e1f815c9.png)

### 分层 k 折叠交叉验证

这种技术类似于 k-fold 交叉验证，只是有一些小的变化。这种方法适用于分层概念，它是一个重新排列数据的过程，以确保每个文件夹或组都是完整数据集的良好代表。处理偏差和方差，这是最好的方法之一。

可以用一个房价的例子来理解，比如有些房子的价格可以比其他房子高很多。为了解决这种情况，分层的 k 折叠交叉验证技术是有用的。

### 保持方法

这种方法是所有方法中最简单的交叉验证技术。在这种方法中，我们需要移除训练数据的子集，并使用它通过在数据集的其余部分上训练来获得预测结果。

这个过程中出现的错误告诉我们模型在未知数据集上的表现。尽管这种方法执行起来很简单，但它仍然面临着高方差的问题，有时还会产生误导性的结果。

## 机器学习中交叉验证与训练/测试分割的比较

*   **训练/测试拆分:**输入数据分为两部分，分别是训练集和测试集，比例为 70:30、80:20 等。它提供了很高的方差，这是最大的缺点之一。
    *   **训练数据:**训练数据用于训练模型，因变量已知。
    *   **测试数据:**测试数据用于根据已经在训练数据上训练的模型进行预测。这与训练数据具有相同的特征，但不是其中的一部分。
*   **交叉验证数据集:**用于克服训练/测试拆分的缺点，将数据集拆分成训练/测试拆分组，并对结果进行平均。如果我们想要优化已在训练数据集上训练的模型以获得最佳性能，则可以使用它。与训练/测试分割相比，它更有效，因为每个观察都用于训练和测试。

## 交叉验证的局限性

交叉验证技术有一些限制，如下所示:

*   对于理想条件，它提供最佳输出。但是对于不一致的数据，可能会产生剧烈的结果。因此，这是交叉验证的一大缺点，因为在机器学习中没有确定的数据类型。
*   在预测建模中，数据在一段时间内演变，因此，它可能面临训练集和验证集之间的差异。例如，如果我们创建一个预测股票市场价值的模型，并且数据是基于前 5 年的股票价值训练的，但是未来 5 年的现实未来价值可能会有很大的不同，因此很难期望这种情况下的正确输出。

## 交叉验证的应用

*   该技术可用于比较不同预测建模方法的性能。
*   它在医学研究领域有很大的应用范围。
*   它也可以用于元分析，因为它已经被医学统计领域的数据科学家使用。

* * *