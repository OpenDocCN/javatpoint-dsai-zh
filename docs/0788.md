# 机器学习中的过拟合

> 原文:[https://www.javatpoint.com/overfitting-in-machine-learning](https://www.javatpoint.com/overfitting-in-machine-learning)

在现实世界中，呈现的数据集永远不会干净和完美。这意味着每个数据集都包含杂质、噪声数据、异常值、缺失数据或不平衡数据。由于这些杂质，会出现不同的问题，影响模型的准确性和性能。其中一个问题是机器学习中的过拟合。*过拟合是一个模型可以表现出来的问题。*

> 如果一个统计模型不能用看不见的数据很好地概括，那么它就被认为是过度的。

在理解过拟合之前，我们需要了解一些基本术语，它们是:

**噪声**:噪声是数据集中存在的无意义或不相关的数据。如果不删除它，它会影响模型的性能。

**偏差**:偏差是由于过于简化机器学习算法而在模型中引入的预测误差。或者是预测值和实际值之间的差异。

**方差**:如果机器学习模型在训练数据集上表现良好，但在测试数据集上表现不佳，那么就会出现方差。

**泛化**:它显示了一个模型在预测看不见的数据方面训练得有多好。

## 什么是过度拟合？

![Overfitting in Machine Learning](../Images/8c4bc84a9de9c528b560a3ded39fae0b.png)

*   过拟合和欠拟合是机器学习模型中的两个主要错误/问题，导致机器学习性能不佳。
*   当模型拟合的数据超过要求时，就会发生过度拟合，它会尝试捕获每个数据点。因此，它开始从数据集中捕获噪声和不准确的数据，这降低了模型的性能。
*   过度拟合的模型在测试/未看到的数据集上表现不准确，并且不能很好地概括。
*   一个过度投入的模型被认为具有低偏差和高方差。

## 理解过度拟合的示例

我们可以用一个一般的例子来理解过度拟合。假设有三个学生，X，Y，Z，三个人都在准备考试。x 只研究了这本书的三个部分，而留下了所有其他部分。y 记性很好，因此记住了整本书。第三个学生 Z 已经学习并练习了所有的问题。所以，在考试中，X 只有在考试有与第 3 节相关的问题时，才能解题。学生 Y 只有在问题与书中给出的完全相同的情况下才能解决问题。学生 Z 将能够以适当的方式解决所有的考试问题。

机器学习也是如此；如果该算法从一小部分数据中学习，它就不能捕获所需的数据点，因此拟合不足。

假设模型学习训练数据集，就像 Y 学生一样。它们在已看到的数据集上表现很好，但在未看到的数据或未知实例上表现很差。在这种情况下，模型被称为过度拟合。

如果该模型在训练数据集和测试/未查看数据集上表现良好，类似于学生 Z，则称其非常适合。

## 如何检测过拟合？

只有在测试数据后，才能检测到模型中的过拟合。要检测问题，我们可以执行**训练/测试分割。**

在数据集的训练-测试分割中，我们可以将数据集分为随机测试数据集和训练数据集。我们使用约占总数据集 80%的训练数据集来训练模型。在训练模型之后，我们用占总数据集 20 %的测试数据集对其进行测试。

![Overfitting in Machine Learning](../Images/1a3fe12eb8e35336b346e7445f08ba75.png)

现在，如果模型在训练数据集上表现良好，但在测试数据集上表现不佳，那么很可能会出现过度拟合的问题。

例如，如果模型对训练数据显示 85%的准确率，对测试数据集显示 50%的准确率，这意味着模型表现不佳。

![Overfitting in Machine Learning](../Images/09b39d443f59232cf6b610c4bb6a5b84.png)

## 防止过度拟合的方法

虽然过拟合是机器学习中的一个错误，会降低模型的性能，但是，我们可以通过几种方式来防止它。利用线性模型，我们可以避免过度拟合；然而，许多现实世界的问题是非线性的。防止模型过度拟合很重要。以下是防止过度拟合的几种方法:

1.  **提前停止**
2.  **用更多数据训练**
3.  **特征选择**
4.  **交叉验证**
5.  数据增加
6.  **正规化**

### 提前停止

在这种技术中，训练在模型开始学习模型内的噪声之前暂停。在这个过程中，在迭代训练模型的同时，测量每次迭代后模型的性能。持续一定次数的迭代，直到新的迭代提高模型的性能。

此后，模型开始过度训练训练数据；因此，我们需要在学习者通过这一点之前停止这个过程。

在模型开始从数据中捕捉噪声之前停止训练过程被称为**提前停止。**

![Overfitting in Machine Learning](../Images/baf6758a3240e8c4e7b01360853b5003.png)

然而，如果训练过早暂停，这种技术可能会导致训练不足的问题。所以，找到适配不足和适配过度之间的“甜蜜点”是非常重要的。

### 用更多数据训练

通过包含更多数据来增加训练集可以提高模型的准确性，因为它提供了更多发现输入和输出变量之间关系的机会。

它可能并不总是能防止过拟合，但这种方式有助于算法更好地检测信号，以最小化误差。

当一个模型被输入更多的训练数据时，它将无法对所有的数据样本进行过度训练，并被迫进行良好的泛化。

但在某些情况下，额外的数据可能会给模型增加更多的噪声；因此，在将数据输入模型之前，我们需要确保数据是干净的，没有不一致性。

### 特征选择

在构建 ML 模型时，我们有许多参数或特征用于预测结果。然而，有时这些特征中的一些对于预测来说是冗余的或不太重要的，并且为此应用了特征选择过程。在特征选择过程中，我们识别训练数据中最重要的特征，并移除其他特征。此外，该过程有助于简化模型并减少数据中的噪声。有些算法有自动特征选择，如果没有，那么我们可以手动执行这个过程。

### 交叉验证

交叉验证是防止过度拟合的有力技术之一。

在一般的 k 重交叉验证技术中，我们将数据集划分为 k 个大小相等的数据子集；这些子集被称为褶皱。

### 日期增加

数据增强是一种数据分析技术，它是添加更多数据以防止过度拟合的替代方法。在这种技术中，不是添加更多的训练数据，而是将已经存在的数据的稍微修改的副本添加到数据集中。

数据扩充技术使得每次模型处理数据样本时，数据样本都可能略有不同。因此，每个数据集对于模型来说都是唯一的，可以防止过度拟合。

### 正规化

如果模型复杂时出现过拟合，我们可以减少特征的数量。然而，过拟合也可能发生在更简单的模型中，更具体地说是线性模型，对于这种情况，正则化技术非常有帮助。

正则化是防止过度拟合的最流行的技术。这是一组迫使学习算法使模型更简单的方法。应用正则化技术可能会略微增加偏差，但会略微降低方差。在该技术中，我们通过添加惩罚项来修改目标函数，该惩罚项对于更复杂的模型具有更高的值。

两种常用的正则化技术是 L1 正则化和 L2 正则化。

### 集成方法

在集成方法中，来自不同机器学习模型的预测被组合以识别最流行的结果。

最常用的集成方法是**装袋和助推。**

在打包中，可以多次选择单个数据点。在收集了几个样本数据集后，这些模型被独立训练，根据任务的类型(即回归或分类)，这些预测的平均值被用来预测更准确的结果。此外，装袋减少了在复杂模型中过度拟合的机会。

在 boosting 中，大量排列在序列中的弱学习者被训练成序列中的每个学习者都从之前学习者的错误中学习。它结合了所有的弱学习者和一个强学习者。此外，它提高了简单模型的预测灵活性。

* * *