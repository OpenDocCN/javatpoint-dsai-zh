# 张量流调试

> 原文:[https://www.javatpoint.com/tensorflow-debugging](https://www.javatpoint.com/tensorflow-debugging)

调试是一项**繁琐**又有挑战性的任务。我们必须通过张量流调试来编写代码和识别问题。通常有许多指南，并且调试过程通常在许多语言和框架中都有很好的记录。

TensorFlow 的调试器名为**tfdbg**TensorFlow debug，它让我们可以观察到运行图的基本工作和状态。这些很难用任何调试器调试，比如 python 中的 **pdb** 。

本教程将教我们如何使用 **tfdbg** 命令行界面调试 nans 和图标的外观，这是张量流中最常见的错误类型。下面给出的是一个低级别的应用编程接口示例。

**python-m tensorlow . python . debug . examples . debug _ mnst**

上面给出的代码训练了一个用于 MNIST 数字图像识别的神经网络，经过几个步骤后，精度在饱和之前增加。

这个错误可以是 INF 和 nans，它们有最常见的错误。现在使用 tfdbg 来调试问题，并确切知道问题从哪里开始。

用 tfdbg 包装 TensorFlow 会话

添加下面一行代码以使用 tfdbg，并使用调试器包装器包含会话对象。

```

From tensorflow.python import debug as tf_debug
sess= tf_debug.LocalCLIDebugWrapperSession (sess)

```

包装类提供了一些额外的特性，包括:命令行界面可以在会话之前和之后调用。如果我们希望控制执行并知道图形的内部状态，请运行()。

可以添加过滤器来辅助诊断。在提供的示例中，有一个名为 tfdbg.has_inf_or_nan 的过滤器，它确定任何中间张量(既不是输入也不是输出)中是否存在 nan 或 inf。

我们总是可以自由地为符合我们需求的定制过滤器编写代码，并且我们可以查看 API 文档来获得相同的附加信息。

## 用 tfdbg 调试 TensorFlow 模型训练，

是时候用包含-debug 标志来训练模型了:

```

python-m
tensorflow.python.debug.examples.debug_mnist-debug

```

提取的数据可以显示在屏幕上，如下图所示:

![TensorFlow Debugging](../Images/c615b99b4f0c62fad963ac4e0006af14.png)

上图是运行启动界面。之后，在提示符下输入 r:

**tfdbg >运行**

这将使 TensorFlow 调试器在下一次会话调用时运行，为测试数据集计算精度。

例如:

![TensorFlow Debugging](../Images/234f2c9b346aa90f8c2d3a864f0828aa.png)

执行 run 后，我们可以使用命令列出张量。

### 常用的张量流调试命令

在 tfdbg >提示符下看到以下命令:请注意，每当我们输入一个命令，就会看到一个全新的显示输出。这类似于浏览器中的网页。我们可以通过单击命令行界面左上角的文本箭头在这些屏幕之间导航。

## tfdbg 命令行界面的功能

类似地，与上面索引的 TensorFlow 调试命令一样，tfdbg CLI 提供了后续的附加功能:

浏览前面以字符开头的 tfdbg 指令。

要浏览前面的 tfdbg 指令，请键入一些带有向上或向下箭头键的字符。Tfdbg 将向我们展示从一个人的态度开始的指令的历史。

要浏览屏幕输出记录，请执行以下两项操作:

单击显示屏左上角顶峰附近带下划线的超链接。要将显示屏输出重定向到优先于屏幕的记录，退出命令将 pt 命令的输出重定向到

```

/tmp/xent_value_slices.txtfile:
tfdbg> pt crosses_entropy/Log:0[:, 0:10] > /tmp/xnt_value_slices.txt

```

## 查找 nans 和 INF

在第一次咨询 **Run ()** 调用中，没有复杂的数值。我们可以通过使用命令 run 或它的简写 r 来跟随 run。

我们还可以使用-t 标志在会话前和会话中进行传输。一次运行()个调用，

Run()调用运行-启动或运行-停止激活时不停止，直到主 **Nan** 或 **inf** 值出现在图形中。这类似于 tensorflow 中过程语言调试器中的条件断点:

```

tfdbg> run -f has_inf_or_nan

```

前面的命令效果很好，因为当创建包装的咨询时，一个称为**的张量已被注册使用。**

```

def my_filter_callable (datum, tensor): 
return len(tensor. Shape) == 0 and tensor == 0
sess.add_tensor_filter('my_filter', my_filters_callable)
The tfdbg run-start prompt Run until our filter is precipitated:
tfdbg> run -f my_filter

```

有关预期签名的更多统计信息，请参见 API 文档，并返回到与 **add_tensor_filter()** 一起使用的谓词可调用的值。

![TensorFlow Debugging](../Images/c4426473da109b248e2b727c5b03076e.png)

因为显示提示在主线上，**有 _inf_or_nan** 过滤掉首先带来的是第四次**会诊**。

**Run()调用:**亚当优化器前进-后退教育跳过图。在本次运行中，36 个中间张量包含 **nan** 或 **inf** 值。

```

tfdbg>pt dross_entropy/Log:0

```

向下滚动一点，我们会看到一些分散的 **inf** 值。如果 **inf** 和 **Nan** 的实例难以用肉眼识别，我们可以使用以下命令执行正则表达式搜索并聚焦输出:

```

tfdbg>/inf

```

或者，作为替代:

```

tfdbg>/(inf|nan)

```

我们还可以使用-s 或 **-numeric_summary** 命令来获得张量中数值排序的摘要:

```

tfdbg>pt -s cross_entropy/Log:0

```

我们可以看到交叉熵/对数:零张量的千个元素中有几个是-INF(负不定式)。

```

tfdbg> ni cross_entropy/Log

```

![TensorFlow Debugging](../Images/2c652a508c24056de9cbab73b456316a.png)

我们看到这个节点有 op 类型日志，它的输入是节点 softmax。然后运行后续命令，更深入地观察输入张量:

```

tfdbg> pt Softmax:0

```

看看输入张量中的值，寻找零:

```

tfdbg>/0\.000

```

现在很明显，可怕的数值的基础是零的节点交叉熵/对数谈话日志。

要找出 python 供应代码中的错误行，请使用 ni 命令的-t 标志来显示节点生产的回溯:

熵/对数

如果我们单击显示顶部的“node_info”，则 **tfdbg** 机械地建议追溯节点的创建。

从回溯中，我们看到 op 构建在下面的行:debug_minist。Py:

```

Diff=y_*tf.log(y)

```

它可以在 python 记录的行中添加 pops 或 tensors，并在它们的帮助下进行标记。

![TensorFlow Debugging](../Images/d9ff4cee5cb854b9e9cd4add94969f58.png)

* * *